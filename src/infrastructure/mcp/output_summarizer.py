"""
Worker ì¶œë ¥ ìë™ ìš”ì•½ ì‹œìŠ¤í…œ

Workerì˜ ê¸´ ì¶œë ¥ì„ ìë™ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ MCP ë„êµ¬ ì œí•œ(25,000 í† í°)ì„ ìš°íšŒí•©ë‹ˆë‹¤.

2ê°€ì§€ ìš”ì•½ ë°©ì‹:
1. LLM ê¸°ë°˜ ìš”ì•½ (ê¸°ë³¸): Claude Haikuë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ëŠ¥ì ìœ¼ë¡œ ìš”ì•½
2. íŒ¨í„´ ë§¤ì¹­ ìš”ì•½ (fallback): ì •ê·œì‹ ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹± ìš”ì•½
"""

import re
import os
from typing import Dict, Tuple, Optional
from pathlib import Path

from ..logging import get_logger
from ..config.env_utils import parse_bool_env

logger = get_logger(__name__, component="OutputSummarizer")

# í™˜ê²½ë³€ìˆ˜ë¡œ LLM ìš”ì•½ on/off (ê¸°ë³¸ê°’: true)
ENABLE_LLM_SUMMARIZATION = parse_bool_env("ENABLE_LLM_SUMMARIZATION", default=True)


class WorkerOutputSummarizer:
    """
    Worker ì¶œë ¥ì„ 3ë‹¨ê³„ë¡œ ìš”ì•½í•˜ëŠ” ì‹œìŠ¤í…œ

    - Level 1 (1ì¤„): ì‘ì—… ìƒíƒœ
    - Level 2 (5-10ì¤„): í•µì‹¬ ë‚´ìš©
    - Level 3 (ì „ì²´): Artifact íŒŒì¼ë¡œ ì €ì¥

    Attributes:
        max_summary_lines: Level 2 ìš”ì•½ ìµœëŒ€ ë¼ì¸ ìˆ˜
    """

    def __init__(self, max_summary_lines: int = 10, use_llm: bool = ENABLE_LLM_SUMMARIZATION):
        """
        Args:
            max_summary_lines: Level 2 ìš”ì•½ ìµœëŒ€ ë¼ì¸ ìˆ˜
            use_llm: LLM ê¸°ë°˜ ìš”ì•½ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜)
        """
        self.max_summary_lines = max_summary_lines
        self.use_llm = use_llm

        # LLM ì‚¬ìš© ì‹œ Anthropic í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.use_llm:
            try:
                import anthropic
                api_key = os.getenv("ANTHROPIC_API_KEY")
                if api_key:
                    self.anthropic_client = anthropic.Anthropic(api_key=api_key)
                    logger.info("LLM-based summarization enabled (Claude Haiku)")
                else:
                    logger.warning("ANTHROPIC_API_KEY not found, falling back to pattern matching")
                    self.use_llm = False
                    self.anthropic_client = None
            except ImportError:
                logger.warning("anthropic package not installed, falling back to pattern matching")
                self.use_llm = False
                self.anthropic_client = None
        else:
            self.anthropic_client = None
            logger.info("Pattern-matching summarization enabled (LLM disabled)")

    def summarize(
        self,
        worker_name: str,
        full_output: str,
        artifact_path: str
    ) -> Dict[str, str]:
        """
        Worker ì¶œë ¥ì„ 3ë‹¨ê³„ë¡œ ìš”ì•½

        Args:
            worker_name: Worker ì´ë¦„
            full_output: ì „ì²´ ì¶œë ¥
            artifact_path: Artifact íŒŒì¼ ê²½ë¡œ

        Returns:
            {
                "one_line": "1ì¤„ ìš”ì•½",
                "summary": "5-10ì¤„ ìš”ì•½",
                "full_path": "artifact ê²½ë¡œ"
            }
        """
        # LLM ê¸°ë°˜ ìš”ì•½ ì‹œë„
        if self.use_llm and self.anthropic_client:
            try:
                llm_summary = self._summarize_with_llm(worker_name, full_output)
                if llm_summary:
                    logger.debug(
                        "LLM summarization successful",
                        worker_name=worker_name,
                        output_length=len(full_output)
                    )
                    return {
                        "one_line": llm_summary["one_line"],
                        "summary": llm_summary["summary"],
                        "full_path": artifact_path
                    }
            except Exception as e:
                logger.warning(
                    "LLM summarization failed, falling back to pattern matching",
                    worker_name=worker_name,
                    error=str(e)
                )

        # Fallback: íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜ ìš”ì•½
        logger.debug(
            "Using pattern-matching summarization",
            worker_name=worker_name
        )
        one_line = self._extract_one_line_summary(worker_name, full_output)
        summary = self._extract_key_summary(full_output)

        return {
            "one_line": one_line,
            "summary": summary,
            "full_path": artifact_path
        }

    def _summarize_with_llm(self, worker_name: str, full_output: str) -> Optional[Dict[str, str]]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ Worker ì¶œë ¥ ìš”ì•½

        Claude Haikuë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê³  ì €ë ´í•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.
        - 1ì¤„ ìš”ì•½: í•µì‹¬ ì‘ì—… ìƒíƒœ
        - 5-10ì¤„ ìš”ì•½: ì¤‘ìš” ë‚´ìš© ë° ê²°ì • ì‚¬í•­

        Args:
            worker_name: Worker ì´ë¦„
            full_output: ì „ì²´ ì¶œë ¥

        Returns:
            {"one_line": "...", "summary": "..."} ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
        """
        if not self.anthropic_client:
            return None

        # ì¶œë ¥ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (í† í° ì œí•œ)
        max_chars = 15000  # ì•½ 5000 í† í°
        truncated_output = full_output[:max_chars]
        if len(full_output) > max_chars:
            truncated_output += "\n\n... (ì¶œë ¥ ìƒëµ) ..."

        # LLM ìš”ì•½ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¤ìŒì€ {worker_name} Workerì˜ ì¶œë ¥ì…ë‹ˆë‹¤. ì´ë¥¼ 2ê°€ì§€ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

1. **1ì¤„ ìš”ì•½** (ìµœëŒ€ 200ì): í•µì‹¬ ì‘ì—… ìƒíƒœ ë° ê²°ê³¼
2. **5-10ì¤„ ìš”ì•½** (ìµœëŒ€ 500ì): ì¤‘ìš” ë‚´ìš©, ë³€ê²½ íŒŒì¼, ì£¼ìš” ê²°ì • ì‚¬í•­

ì¶œë ¥ í˜•ì‹:
```
ONE_LINE: (1ì¤„ ìš”ì•½)
SUMMARY:
(5-10ì¤„ ìš”ì•½)
```

Worker ì¶œë ¥:
---
{truncated_output}
---

ìš”ì•½ì„ ì‹œì‘í•˜ì„¸ìš”:"""

        try:
            # Claude Haiku í˜¸ì¶œ (ë¹ ë¥´ê³  ì €ë ´)
            response = self.anthropic_client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=1024,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )

            # ì‘ë‹µ íŒŒì‹± (ì•ˆì „í•œ ì ‘ê·¼)
            if not response.content or len(response.content) == 0:
                logger.warning(
                    "LLM response content is empty",
                    worker_name=worker_name
                )
                return None

            # content[0].textê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì ‘ê·¼
            content_block = response.content[0]
            if not hasattr(content_block, 'text') or not content_block.text:
                logger.warning(
                    "LLM response content[0].text is None or missing",
                    worker_name=worker_name,
                    content_block_type=type(content_block).__name__
                )
                return None

            summary_text = content_block.text.strip()

            # ONE_LINE ì¶”ì¶œ
            one_line_match = re.search(r"ONE_LINE:\s*(.+?)(?:\n|$)", summary_text, re.DOTALL)
            one_line = one_line_match.group(1).strip() if one_line_match else ""

            # SUMMARY ì¶”ì¶œ
            summary_match = re.search(r"SUMMARY:\s*(.+)", summary_text, re.DOTALL)
            summary = summary_match.group(1).strip() if summary_match else ""

            # ê²€ì¦
            if not one_line or not summary:
                logger.warning(
                    "LLM summary parsing failed",
                    worker_name=worker_name,
                    response_preview=summary_text[:200]
                )
                return None

            return {
                "one_line": one_line[:200],  # ìµœëŒ€ 200ì
                "summary": summary[:500]  # ìµœëŒ€ 500ì
            }

        except Exception as e:
            logger.warning(
                "LLM API call failed",
                worker_name=worker_name,
                error=str(e)
            )
            return None

    def _extract_one_line_summary(self, worker_name: str, output: str) -> str:
        """
        1ì¤„ ìš”ì•½ ì¶”ì¶œ

        ì „ëµ:
        1. "## ìš”ì•½" ì„¹ì…˜ì˜ ì²« ì¤„ ì°¾ê¸°
        2. ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í—¤ë”(##) ì°¾ê¸°
        3. ì—†ìœ¼ë©´ ì²« 5ë‹¨ì–´ + "..."

        Args:
            worker_name: Worker ì´ë¦„
            output: ì „ì²´ ì¶œë ¥

        Returns:
            1ì¤„ ìš”ì•½
        """
        # ì „ëµ 1: "## ìš”ì•½" ë˜ëŠ” "## Summary" ì„¹ì…˜ ì°¾ê¸°
        summary_match = re.search(
            r'##\s*(ìš”ì•½|Summary|ê²°ë¡ |Conclusion)\s*\n(.+?)(?:\n|$)',
            output,
            re.IGNORECASE
        )
        if summary_match:
            return summary_match.group(2).strip()[:200]  # ìµœëŒ€ 200ì

        # ì „ëµ 2: ì²« ë²ˆì§¸ ## í—¤ë” ì°¾ê¸°
        header_match = re.search(r'##\s*(.+?)(?:\n|$)', output)
        if header_match:
            return header_match.group(1).strip()[:200]

        # ì „ëµ 3: ì²« 5ë‹¨ì–´
        words = output.split()[:10]
        if words:
            truncated = ' '.join(words)
            return f"[{worker_name}] {truncated[:150]}..."

        return f"[{worker_name}] ì‘ì—… ì™„ë£Œ"

    def _extract_key_summary(self, output: str) -> str:
        """
        í•µì‹¬ ìš”ì•½ ì¶”ì¶œ (5-10ì¤„)

        ì „ëµ:
        1. "## ìš”ì•½" ì„¹ì…˜ ì „ì²´ ì¶”ì¶œ
        2. ì—†ìœ¼ë©´ ì£¼ìš” í—¤ë”(##) ëª©ë¡ ì¶”ì¶œ
        3. ì—†ìœ¼ë©´ ì²« 10ì¤„ ì¶”ì¶œ

        Args:
            output: ì „ì²´ ì¶œë ¥

        Returns:
            5-10ì¤„ ìš”ì•½
        """
        lines = output.split('\n')

        # ì „ëµ 1: "## ìš”ì•½" ì„¹ì…˜ ì¶”ì¶œ
        summary_section = self._extract_section(output, r'##\s*(ìš”ì•½|Summary|ê²°ë¡ |Conclusion)')
        if summary_section:
            summary_lines = summary_section.split('\n')[:self.max_summary_lines]
            return '\n'.join(summary_lines)

        # ì „ëµ 2: ì£¼ìš” í—¤ë”(##) ëª©ë¡ ì¶”ì¶œ
        headers = re.findall(r'##\s*(.+?)(?:\n|$)', output)
        if headers:
            header_list = '\n'.join(f"- {h.strip()}" for h in headers[:self.max_summary_lines])
            return f"**ì£¼ìš” ì„¹ì…˜:**\n{header_list}"

        # ì „ëµ 3: ì²« Nì¤„ ì¶”ì¶œ (ê³µë°±/êµ¬ë¶„ì„  ì œì™¸)
        meaningful_lines = [
            line for line in lines
            if line.strip() and not line.strip().startswith('=') and not line.strip().startswith('-')
        ]
        truncated_lines = meaningful_lines[:self.max_summary_lines]
        return '\n'.join(truncated_lines)

    def _extract_section(self, text: str, section_header_pattern: str) -> str:
        """
        íŠ¹ì • ì„¹ì…˜ ì¶”ì¶œ

        Args:
            text: ì „ì²´ í…ìŠ¤íŠ¸
            section_header_pattern: ì„¹ì…˜ í—¤ë” ì •ê·œì‹ íŒ¨í„´

        Returns:
            ì„¹ì…˜ ë‚´ìš© (í—¤ë” ì œì™¸)
        """
        # ì„¹ì…˜ ì‹œì‘ ì°¾ê¸°
        match = re.search(section_header_pattern, text, re.IGNORECASE)
        if not match:
            return ""

        start = match.end()

        # ë‹¤ìŒ ## í—¤ë”ê¹Œì§€ ë˜ëŠ” ëê¹Œì§€
        next_header = re.search(r'\n##\s', text[start:])
        if next_header:
            end = start + next_header.start()
        else:
            end = len(text)

        return text[start:end].strip()

    def format_summary_output(
        self,
        worker_name: str,
        summary: Dict[str, str]
    ) -> str:
        """
        ìš”ì•½ì„ í¬ë§·íŒ…ëœ ë¬¸ìì—´ë¡œ ë³€í™˜

        Args:
            worker_name: Worker ì´ë¦„
            summary: summarize() ë°˜í™˜ê°’

        Returns:
            í¬ë§·íŒ…ëœ ìš”ì•½ ë¬¸ìì—´
        """
        return f"""## ğŸ“‹ [{worker_name.upper()} ìš”ì•½ - Manager ì „ë‹¬ìš©]

**âœ… ìƒíƒœ: ì‘ì—… ì™„ë£Œ**

**í•µì‹¬ ë‚´ìš©**:
{summary['summary']}

**ìš”ì•½**: {summary['one_line']}

---
**[ì „ì²´ ë¡œê·¸: artifact `{Path(summary['full_path']).stem}`]**

âš ï¸ **ì¤‘ìš”**: ì´ WorkerëŠ” ì´ë¯¸ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ë™ì¼í•œ Workerë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.
"""


def test_summarizer():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸"""
    summarizer = WorkerOutputSummarizer()

    # í…ŒìŠ¤íŠ¸ ì¶œë ¥
    test_output = """## ìš”êµ¬ì‚¬í•­ ë¶„ì„

ì‚¬ìš©ìëŠ” FastAPI CRUD APIë¥¼ ì›í•©ë‹ˆë‹¤.

## êµ¬í˜„ ê³„íš

1. ëª¨ë¸ ì •ì˜
2. API ë¼ìš°í„° ì‘ì„±
3. í…ŒìŠ¤íŠ¸ ì‘ì„±

## ì˜ˆìƒ ìœ„í—˜ ìš”ì†Œ

- DB ì—°ê²° ì„¤ì • í•„ìš”
- ì¸ì¦ ì²˜ë¦¬ ê³ ë ¤
"""

    summary = summarizer.summarize(
        worker_name="planner",
        full_output=test_output,
        artifact_path="/path/to/artifact/planner_20251022_001.txt"
    )

    formatted = summarizer.format_summary_output("planner", summary)
    print(formatted)
    print("\nâœ… Summarizer í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


if __name__ == "__main__":
    test_summarizer()

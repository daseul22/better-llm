"""
Worker Agent Tools - Worker Agentë“¤ì„ Custom Toolë¡œ ë˜í•‘

ê° Worker Agentë¥¼ Claude Agent SDKì˜ Custom Toolë¡œ ë§Œë“¤ì–´,
Manager Agentê°€ í•„ìš”í•  ë•Œ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

Phase 2-1 Level 3: WorkerExecutor ë° Level 1 ëª¨ë“ˆê³¼ í†µí•©í•˜ì—¬ ì¤‘ë³µ ì½”ë“œ ì œê±°
"""

from typing import Any, Dict, Callable, Optional
from pathlib import Path
import logging
import os

from claude_agent_sdk import tool, create_sdk_mcp_server

from ..claude import WorkerAgent
from domain.services import MetricsCollector
from ..config import JsonConfigLoader, get_project_root
from ..logging import get_logger

# Level 1 ë° Level 2 ëª¨ë“ˆ Import
from infrastructure.mcp.review_cycle_manager import ReviewCycleManager
from infrastructure.mcp.commit_validator import CommitSafetyValidator
from infrastructure.mcp.workflow_callback_handler import (
    WorkflowCallbackHandler,
    WorkflowEventType
)
from infrastructure.mcp.error_statistics_manager import ErrorStatisticsManager
from infrastructure.mcp.parallel_executor import ParallelExecutor
from infrastructure.mcp.worker_executor import WorkerExecutor, WorkerExecutionContext

logger = get_logger(__name__, component="WorkerTools")


# ============================================================================
# ì „ì—­ ë³€ìˆ˜ (Global State Management)
# ============================================================================

# Worker Agent ì¸ìŠ¤í„´ìŠ¤ë“¤
_WORKER_AGENTS: Dict[str, WorkerAgent] = {}

# WorkerExecutor ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_WORKER_EXECUTOR: Optional[WorkerExecutor] = None

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° (ì„ íƒì )
_METRICS_COLLECTOR: Optional[MetricsCollector] = None
_CURRENT_SESSION_ID: Optional[str] = None

# Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± (TUIì—ì„œ ì„¤ì •)
_WORKER_OUTPUT_CALLBACK: Optional[Callable] = None


# ============================================================================
# Workerë³„ íƒ€ì„ì•„ì›ƒ ì„¤ì •
# ============================================================================

def _get_timeout_from_env(worker_name: str, default: int) -> int:
    """
    í™˜ê²½ë³€ìˆ˜ì—ì„œ íƒ€ì„ì•„ì›ƒ ê°’ ê°€ì ¸ì˜¤ê¸° (ì•ˆì „í•œ int ë³€í™˜)

    Args:
        worker_name: Worker ì´ë¦„ (ì˜ˆ: "planner", "coder")
        default: ê¸°ë³¸ê°’

    Returns:
        íƒ€ì„ì•„ì›ƒ ê°’ (ì´ˆ)
    """
    env_var = f"WORKER_TIMEOUT_{worker_name.upper()}"
    value = os.getenv(env_var)

    if value is None:
        return default

    try:
        return int(value)
    except ValueError:
        logger.warning(
            f"í™˜ê²½ë³€ìˆ˜ {env_var}ì˜ ê°’ '{value}'ì„(ë¥¼) ì •ìˆ˜ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            f"ê¸°ë³¸ê°’ {default}ì´ˆë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )
        return default


# Workerë³„ íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ ë‹¨ìœ„, í™˜ê²½ë³€ìˆ˜ > system_config.json > ê¸°ë³¸ê°’ ìˆœ)
_WORKER_TIMEOUTS = {
    "planner": _get_timeout_from_env("planner", 300),
    "coder": _get_timeout_from_env("coder", 600),
    "reviewer": _get_timeout_from_env("reviewer", 300),
    "tester": _get_timeout_from_env("tester", 600),
    "committer": _get_timeout_from_env("committer", 180),
    "ideator": _get_timeout_from_env("ideator", 300),
    "product_manager": _get_timeout_from_env("product_manager", 300),
}


def _load_worker_timeouts_from_config():
    """
    system_config.jsonì—ì„œ Worker íƒ€ì„ì•„ì›ƒ ë¡œë“œ

    í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©,
    ì—†ìœ¼ë©´ system_config.json ê°’ ì‚¬ìš©,
    ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    """
    global _WORKER_TIMEOUTS

    try:
        from ..config import load_system_config

        config = load_system_config()
        timeouts = config.get("timeouts", {})

        # í™˜ê²½ë³€ìˆ˜ > system_config.json > ê¸°ë³¸ê°’ ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„
        _WORKER_TIMEOUTS["planner"] = _get_timeout_from_env(
            "planner", timeouts.get("planner_timeout", 300)
        )
        _WORKER_TIMEOUTS["coder"] = _get_timeout_from_env(
            "coder", timeouts.get("coder_timeout", 600)
        )
        _WORKER_TIMEOUTS["reviewer"] = _get_timeout_from_env(
            "reviewer", timeouts.get("reviewer_timeout", 300)
        )
        _WORKER_TIMEOUTS["tester"] = _get_timeout_from_env(
            "tester", timeouts.get("tester_timeout", 600)
        )
        _WORKER_TIMEOUTS["committer"] = _get_timeout_from_env(
            "committer", timeouts.get("committer_timeout", 180)
        )
        _WORKER_TIMEOUTS["ideator"] = _get_timeout_from_env(
            "ideator", timeouts.get("ideator_timeout", 300)
        )
        _WORKER_TIMEOUTS["product_manager"] = _get_timeout_from_env(
            "product_manager", timeouts.get("product_manager_timeout", 300)
        )

        logger.debug(f"Worker íƒ€ì„ì•„ì›ƒ ì„¤ì • ë¡œë“œ ì™„ë£Œ: {_WORKER_TIMEOUTS}")

    except Exception as e:
        logger.warning(f"system_config.jsonì—ì„œ íƒ€ì„ì•„ì›ƒ ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ê°’ ì‚¬ìš©.")


# ============================================================================
# ì´ˆê¸°í™” ë° ì„¤ì • í•¨ìˆ˜
# ============================================================================

def initialize_workers(config_path: Path):
    """
    Worker Agentë“¤ì„ ì´ˆê¸°í™”í•˜ê³  WorkerExecutor ë° ParallelExecutorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        config_path: Agent ì„¤ì • íŒŒì¼ ê²½ë¡œ
    """
    global _WORKER_AGENTS, _WORKER_EXECUTOR, _PARALLEL_EXECUTOR

    # system_config.jsonì—ì„œ íƒ€ì„ì•„ì›ƒ ì„¤ì • ë¡œë“œ
    _load_worker_timeouts_from_config()

    # system_config.jsonì—ì„œ max_review_iterations ë¡œë“œ
    max_cycles = 3
    try:
        from ..config import load_system_config
        config = load_system_config()
        max_cycles = config.get("workflow_limits", {}).get(
            "max_review_iterations", 3
        )
        logger.info(f"âœ… Review cycle ìµœëŒ€ íšŸìˆ˜: {max_cycles}íšŒ")
    except Exception as e:
        logger.warning(f"max_review_iterations ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ê°’ 3 ì‚¬ìš©.")
        max_cycles = 3

    # Worker Agent ì´ˆê¸°í™”
    loader = JsonConfigLoader(get_project_root())
    worker_configs = loader.load_agent_configs()

    for config in worker_configs:
        worker = WorkerAgent(config)
        _WORKER_AGENTS[config.name] = worker
        logger.info(
            "Worker agent initialized",
            worker_name=config.name,
            role=config.role,
            model=config.model
        )

    # WorkerExecutor ì´ˆê¸°í™” (Level 1 ë§¤ë‹ˆì €ë“¤ê³¼ í•¨ê»˜)
    _WORKER_EXECUTOR = WorkerExecutor(
        review_manager=ReviewCycleManager(max_cycles=max_cycles),
        commit_validator=CommitSafetyValidator(),
        callback_handler=WorkflowCallbackHandler(),
        error_manager=ErrorStatisticsManager()
    )
    logger.info("âœ… WorkerExecutor initialized with Level 1 managers")

    # ParallelExecutorëŠ” execute_parallel_tasksì—ì„œ ë™ì ìœ¼ë¡œ ìƒì„±
    # (task_executor ì½œë°± í•¨ìˆ˜ í•„ìš”)
    logger.info("âœ… Worker initialization completed")


def set_metrics_collector(collector: MetricsCollector, session_id: str) -> None:
    """
    ë©”íŠ¸ë¦­ ì»¬ë ‰í„° ì„¤ì • (TUI/CLIì—ì„œ í˜¸ì¶œ)

    Args:
        collector: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
        session_id: í˜„ì¬ ì„¸ì…˜ ID
    """
    global _METRICS_COLLECTOR, _CURRENT_SESSION_ID
    _METRICS_COLLECTOR = collector
    _CURRENT_SESSION_ID = session_id
    logger.info("Metrics collector configured", session_id=session_id)


def update_session_id(session_id: str) -> None:
    """
    í˜„ì¬ ì„¸ì…˜ ID ì—…ë°ì´íŠ¸

    Args:
        session_id: ìƒˆ ì„¸ì…˜ ID
    """
    global _CURRENT_SESSION_ID
    _CURRENT_SESSION_ID = session_id
    logger.info("Session ID updated", session_id=session_id)


def set_workflow_callback(callback: Optional[Callable]) -> None:
    """
    ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°± ì„¤ì •

    Args:
        callback: ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
                  ì‹œê·¸ë‹ˆì²˜: callback(worker_name: str, status: str, error: Optional[str])
    """
    global _WORKER_EXECUTOR

    if not _WORKER_EXECUTOR:
        logger.warning("WorkerExecutor not initialized, callback not set")
        return

    if callback:
        # ê¸°ì¡´ ì½œë°±ì„ WorkflowCallbackHandler í˜•ì‹ìœ¼ë¡œ ë˜í•‘
        def wrapped_callback(context: Dict[str, Any]) -> None:
            callback(
                context.get("worker_name"),
                context.get("status"),
                context.get("error")
            )

        # ê° ì´ë²¤íŠ¸ì— ì½œë°± ë“±ë¡
        _WORKER_EXECUTOR.callback_handler.register_callback(
            WorkflowEventType.WORKER_RUNNING, wrapped_callback
        )
        _WORKER_EXECUTOR.callback_handler.register_callback(
            WorkflowEventType.WORKER_COMPLETED, wrapped_callback
        )
        _WORKER_EXECUTOR.callback_handler.register_callback(
            WorkflowEventType.WORKER_FAILED, wrapped_callback
        )

    logger.info("âœ… ì›Œí¬í”Œë¡œìš° ì½œë°± ì„¤ì • ì™„ë£Œ")


def set_worker_output_callback(callback: Optional[Callable]) -> None:
    """
    Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •

    Args:
        callback: Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
                  ì‹œê·¸ë‹ˆì²˜: callback(worker_name: str, chunk: str)
    """
    global _WORKER_OUTPUT_CALLBACK
    _WORKER_OUTPUT_CALLBACK = callback
    logger.info("âœ… Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì • ì™„ë£Œ")


def reset_review_cycle() -> None:
    """
    Review cycleì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    ìƒˆ ì‘ì—… ì‹œì‘ ì‹œ í˜¸ì¶œí•˜ì—¬ ì´ì „ ì‘ì—…ì˜ review countê°€ ëˆ„ì ë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
    """
    global _WORKER_EXECUTOR

    if _WORKER_EXECUTOR:
        _WORKER_EXECUTOR.reset_review_cycle()
        logger.info("ğŸ”„ Review cycle has been reset")
    else:
        logger.warning("WorkerExecutor not initialized, cannot reset review cycle")


# ============================================================================
# ì—ëŸ¬ í†µê³„ ì¡°íšŒ (ErrorStatisticsManager ìœ„ì„)
# ============================================================================

def get_error_statistics() -> Dict[str, Any]:
    """
    ì—ëŸ¬ í†µê³„ ì¡°íšŒ

    Returns:
        ê° Workerì˜ ì‹œë„/ì‹¤íŒ¨ í†µê³„ ë° ì—ëŸ¬ìœ¨
    """
    global _WORKER_EXECUTOR

    if _WORKER_EXECUTOR:
        return _WORKER_EXECUTOR.get_error_summary()

    # í´ë°±: WorkerExecutorê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ë¹ˆ í†µê³„ ë°˜í™˜
    logger.warning("WorkerExecutor not initialized, returning empty statistics")
    return {}


def reset_error_statistics():
    """
    ì—ëŸ¬ í†µê³„ ì´ˆê¸°í™”
    """
    global _WORKER_EXECUTOR

    if _WORKER_EXECUTOR:
        _WORKER_EXECUTOR.reset_error_statistics()
        logger.info("âœ… ì—ëŸ¬ í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")
    else:
        logger.warning("WorkerExecutor not initialized, cannot reset statistics")


def log_error_summary():
    """
    ì—ëŸ¬ í†µê³„ ìš”ì•½ ë¡œê·¸ ì¶œë ¥
    """
    stats = get_error_statistics()
    if not stats:
        logger.info("ğŸ“Š ì—ëŸ¬ í†µê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    logger.info("=" * 60)
    logger.info("ğŸ“Š Worker Tools ì—ëŸ¬ í†µê³„")
    logger.info("=" * 60)

    for worker_name, data in stats.items():
        logger.info(
            f"[{worker_name.upper()}] "
            f"ì‹œë„: {data['attempts']}, "
            f"ì„±ê³µ: {data['successes']}, "
            f"ì‹¤íŒ¨: {data['failures']}, "
            f"ì—ëŸ¬ìœ¨: {data['error_rate']}%"
        )

    logger.info("=" * 60)


# ============================================================================
# MCP Tool í•¨ìˆ˜ë“¤ (7ê°œ Worker Tools)
# ============================================================================

@tool(
    "execute_planner_task",
    "Planner Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
    {
        "task_description": {
            "type": "string",
            "description": "ì‘ì—… ì„¤ëª…"
        }
    }
)
async def execute_planner_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Planner Agent ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    context = WorkerExecutionContext(
        worker_name="planner",
        task_description=args["task_description"],
        use_retry=True,
        timeout=_WORKER_TIMEOUTS["planner"],
        session_id=_CURRENT_SESSION_ID,
        metrics_collector=_METRICS_COLLECTOR,
        worker_agent=_WORKER_AGENTS.get("planner"),
        worker_output_callback=_WORKER_OUTPUT_CALLBACK
    )
    return await _WORKER_EXECUTOR.execute(context)


@tool(
    "execute_coder_task",
    "Coder Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì½”ë“œ ì‘ì„±, ìˆ˜ì •, ë¦¬íŒ©í† ë§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
    {
        "task_description": {
            "type": "string",
            "description": "ì‘ì—… ì„¤ëª…"
        }
    }
)
async def execute_coder_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Coder Agent ì‹¤í–‰

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    context = WorkerExecutionContext(
        worker_name="coder",
        task_description=args["task_description"],
        use_retry=False,
        timeout=_WORKER_TIMEOUTS["coder"],
        session_id=_CURRENT_SESSION_ID,
        metrics_collector=_METRICS_COLLECTOR,
        worker_agent=_WORKER_AGENTS.get("coder"),
        worker_output_callback=_WORKER_OUTPUT_CALLBACK
    )
    return await _WORKER_EXECUTOR.execute(context)


@tool(
    "execute_tester_task",
    "Tester Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ì‹¤í–‰ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
    {
        "task_description": {
            "type": "string",
            "description": "ì‘ì—… ì„¤ëª…"
        }
    }
)
async def execute_tester_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Tester Agent ì‹¤í–‰

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    context = WorkerExecutionContext(
        worker_name="tester",
        task_description=args["task_description"],
        use_retry=False,
        timeout=_WORKER_TIMEOUTS["tester"],
        session_id=_CURRENT_SESSION_ID,
        metrics_collector=_METRICS_COLLECTOR,
        worker_agent=_WORKER_AGENTS.get("tester"),
        worker_output_callback=_WORKER_OUTPUT_CALLBACK
    )
    return await _WORKER_EXECUTOR.execute(context)


@tool(
    "execute_reviewer_task",
    "Reviewer Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì½”ë“œ ë¦¬ë·° ë° í’ˆì§ˆ ê²€ì¦ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
    {
        "task_description": {
            "type": "string",
            "description": "ë¦¬ë·° ìš”ì²­ ë‚´ìš©"
        }
    }
)
async def execute_reviewer_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Reviewer Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì½”ë“œ ë¦¬ë·° ë° í’ˆì§ˆ ê²€ì¦ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

    Review cycleì€ ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ìµœëŒ€ íšŸìˆ˜ê°€ ì œí•œë©ë‹ˆë‹¤.
    (ê¸°ë³¸ê°’: 3íšŒ, system_config.jsonì˜ 'workflow_limits.max_review_iterations'ë¡œ ì¡°ì • ê°€ëŠ¥)

    Args:
        args: {"task_description": "ë¦¬ë·° ìš”ì²­ ë‚´ìš©"}

    Returns:
        Dict[str, Any]: Agent ì‹¤í–‰ ê²°ê³¼
            - content: [{"type": "text", "text": "ë¦¬ë·° ê²°ê³¼"}]

    Raises:
        Exception: Review cycleì´ ìµœëŒ€ì¹˜ë¥¼ ì´ˆê³¼í•œ ê²½ìš°

    Note:
        - Review cycleì€ Reviewer â†’ Coder â†’ Reviewer íŒ¨í„´ì„ ê°ì§€í•˜ì—¬ ì¦ê°€í•©ë‹ˆë‹¤.
        - ìµœëŒ€ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ ì‹¤í–‰ì´ ì¤‘ë‹¨ë˜ë©°, ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
        - ìƒˆ ì‘ì—… ì‹œì‘ ì‹œ(Planner ë˜ëŠ” Coder í˜¸ì¶œ) Review cycleì´ ìë™ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
    """
    context = WorkerExecutionContext(
        worker_name="reviewer",
        task_description=args["task_description"],
        use_retry=False,
        timeout=_WORKER_TIMEOUTS["reviewer"],
        session_id=_CURRENT_SESSION_ID,
        metrics_collector=_METRICS_COLLECTOR,
        worker_agent=_WORKER_AGENTS.get("reviewer"),
        worker_output_callback=_WORKER_OUTPUT_CALLBACK
    )
    return await _WORKER_EXECUTOR.execute(context)


@tool(
    "execute_committer_task",
    "Committer Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. Git ì»¤ë°‹ ìƒì„±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
    {
        "task_description": {
            "type": "string",
            "description": "ì‘ì—… ì„¤ëª…"
        }
    }
)
async def execute_committer_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Committer Agent ì‹¤í–‰ (ë³´ì•ˆ ê²€ì¦ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    # ë³´ì•ˆ ê²€ì¦ ìˆ˜í–‰
    is_safe, error_msg = await _WORKER_EXECUTOR.commit_validator.validate()
    if not is_safe:
        logger.warning(f"[Committer Tool] ì»¤ë°‹ ê±°ë¶€ (ë¯¼ê° ì •ë³´ ê°ì§€): {error_msg}")
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"âŒ ì»¤ë°‹ ê±°ë¶€ (ë³´ì•ˆ ê²€ì¦ ì‹¤íŒ¨):\n\n{error_msg}"
                }
            ]
        }

    logger.info("[Committer Tool] ë³´ì•ˆ ê²€ì¦ í†µê³¼ - Committer Agent ì‹¤í–‰")

    context = WorkerExecutionContext(
        worker_name="committer",
        task_description=args["task_description"],
        use_retry=False,
        timeout=_WORKER_TIMEOUTS["committer"],
        session_id=_CURRENT_SESSION_ID,
        metrics_collector=_METRICS_COLLECTOR,
        worker_agent=_WORKER_AGENTS.get("committer"),
        worker_output_callback=_WORKER_OUTPUT_CALLBACK
    )
    return await _WORKER_EXECUTOR.execute(context)


@tool(
    "execute_ideator_task",
    "Ideator Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì°½ì˜ì  ì•„ì´ë””ì–´ ìƒì„± ë° ë¸Œë ˆì¸ìŠ¤í† ë°ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
    {
        "task_description": {
            "type": "string",
            "description": "ì‘ì—… ì„¤ëª…"
        }
    }
)
async def execute_ideator_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Ideator Agent ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    context = WorkerExecutionContext(
        worker_name="ideator",
        task_description=args["task_description"],
        use_retry=True,
        timeout=_WORKER_TIMEOUTS["ideator"],
        session_id=_CURRENT_SESSION_ID,
        metrics_collector=_METRICS_COLLECTOR,
        worker_agent=_WORKER_AGENTS.get("ideator"),
        worker_output_callback=_WORKER_OUTPUT_CALLBACK
    )
    return await _WORKER_EXECUTOR.execute(context)


@tool(
    "execute_product_manager_task",
    "Product Manager Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì œí’ˆ ê¸°íš ë° ìš”êµ¬ì‚¬í•­ ì •ì˜ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.",
    {
        "task_description": {
            "type": "string",
            "description": "ì‘ì—… ì„¤ëª…"
        }
    }
)
async def execute_product_manager_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Product Manager Agent ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    context = WorkerExecutionContext(
        worker_name="product_manager",
        task_description=args["task_description"],
        use_retry=True,
        timeout=_WORKER_TIMEOUTS["product_manager"],
        session_id=_CURRENT_SESSION_ID,
        metrics_collector=_METRICS_COLLECTOR,
        worker_agent=_WORKER_AGENTS.get("product_manager"),
        worker_output_callback=_WORKER_OUTPUT_CALLBACK
    )
    return await _WORKER_EXECUTOR.execute(context)


# ============================================================================
# ë³‘ë ¬ ì‹¤í–‰ Tool (ParallelExecutor í†µí•©)
# ============================================================================

@tool(
    "execute_parallel_tasks",
    "ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSONì„ ë°›ì•„ì„œ Taskë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.",
    {
        "plan_json": {
            "type": "string",
            "description": "Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSON ë¬¸ìì—´"
        }
    }
)
async def execute_parallel_tasks(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ Tool

    Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSONì„ ë°›ì•„ì„œ
    ParallelExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ Taskë“¤ì„ ë³‘ë ¬ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Args:
        args: {
            "plan_json": "Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSON ë¬¸ìì—´"
        }

    Returns:
        {
            "content": [{"type": "text", "text": "ì‹¤í–‰ ê²°ê³¼"}],
            "success": True/False,
            "metadata": {
                "completed_tasks": int,
                "failed_tasks": int,
                "total_duration": float,
                "speedup_factor": float
            }
        }
    """
    from src.domain.models.parallel_task import ParallelTask

    try:
        # ParallelExecutor ë™ì  ìƒì„±
        # Coder Workerë¥¼ task_executorë¡œ ë˜í•‘
        async def coder_task_executor(task: ParallelTask) -> str:
            """ë‹¨ì¼ Task ì‹¤í–‰ (Coder Worker í˜¸ì¶œ)"""
            coder_agent = _WORKER_AGENTS.get("coder")
            if not coder_agent:
                raise RuntimeError("Coder Agentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # Coderì—ê²Œ ì „ë‹¬í•  ì‘ì—… ì„¤ëª…
            # Task descriptionì— target_files ì •ë³´ ì¶”ê°€
            task_description = task.description
            if task.target_files:
                task_description += f"\n\n**Target Files**: {', '.join(task.target_files)}"

            result = ""
            async for chunk in coder_agent.execute_task(task_description):
                result += chunk
                # Worker ì¶œë ¥ ì½œë°± í˜¸ì¶œ (TUI ìŠ¤íŠ¸ë¦¬ë°)
                if _WORKER_OUTPUT_CALLBACK:
                    _WORKER_OUTPUT_CALLBACK("coder", chunk)

            return result

        # ParallelExecutor ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        executor = ParallelExecutor(
            task_executor=coder_task_executor,
            max_concurrent_tasks=4
        )

        # JSON íŒŒì‹± ë° ì‹¤í–‰
        plan = executor.parse_plan(args["plan_json"])

        logger.info(
            f"[parallel_executor] {len(plan.tasks)}ê°œ Task ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘",
            task_ids=[task.id for task in plan.tasks]
        )

        # ë³‘ë ¬ ì‹¤í–‰
        execution_result = await executor.execute(plan)

        # ê²°ê³¼ í¬ë§·íŒ…
        result_lines = []
        result_lines.append(f"ğŸš€ ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ\n")
        result_lines.append(f"ğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
        result_lines.append(f"   - ì„±ê³µ: {len(execution_result.completed_tasks)}ê°œ")
        result_lines.append(f"   - ì‹¤íŒ¨: {len(execution_result.failed_tasks)}ê°œ")
        result_lines.append(f"   - ì‹¤í–‰ ì‹œê°„: {execution_result.total_duration:.1f}ì´ˆ")
        result_lines.append(f"   - ì†ë„ í–¥ìƒ: {execution_result.speedup_factor:.2f}x")
        result_lines.append(f"   - ì„±ê³µë¥ : {execution_result.success_rate * 100:.0f}%\n")

        # ì™„ë£Œëœ Task ìƒì„¸
        if execution_result.completed_tasks:
            result_lines.append("âœ… ì™„ë£Œëœ Task:")
            for task in execution_result.completed_tasks:
                result_lines.append(f"   - [{task.id}] {task.description}")
                result_lines.append(f"     íŒŒì¼: {', '.join(task.target_files)}")
                if task.duration_seconds():
                    result_lines.append(f"     ì‹¤í–‰ ì‹œê°„: {task.duration_seconds():.1f}ì´ˆ")
                result_lines.append("")

        # ì‹¤íŒ¨í•œ Task ìƒì„¸
        if execution_result.failed_tasks:
            result_lines.append("âŒ ì‹¤íŒ¨í•œ Task:")
            for task in execution_result.failed_tasks:
                result_lines.append(f"   - [{task.id}] {task.description}")
                result_lines.append(f"     ì—ëŸ¬: {task.error}")
                result_lines.append("")

        # í†µí•© ì£¼ì˜ì‚¬í•­
        if plan.integration_notes:
            result_lines.append(f"ğŸ“ í†µí•© ì‹œ ì£¼ì˜ì‚¬í•­:")
            result_lines.append(f"   {plan.integration_notes}\n")

        result_text = "\n".join(result_lines)

        logger.info(
            f"[parallel_executor] ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ",
            completed=len(execution_result.completed_tasks),
            failed=len(execution_result.failed_tasks),
            duration=execution_result.total_duration
        )

        return {
            "content": [{"type": "text", "text": result_text}],
            "success": execution_result.all_succeeded,
            "metadata": {
                "completed_tasks": len(execution_result.completed_tasks),
                "failed_tasks": len(execution_result.failed_tasks),
                "total_duration": execution_result.total_duration,
                "speedup_factor": execution_result.speedup_factor,
                "success_rate": execution_result.success_rate
            }
        }

    except Exception as e:
        logger.error(f"[parallel_executor] ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        return {
            "content": [{"type": "text", "text": f"âŒ ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}"}],
            "success": False,
            "error": str(e)
        }


# ============================================================================
# MCP ì„œë²„ ìƒì„±
# ============================================================================

def create_worker_tools_server():
    """
    Worker Toolë“¤ì„ í¬í•¨í•˜ëŠ” MCP ì„œë²„ ìƒì„±

    Returns:
        MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤
    """
    server = create_sdk_mcp_server(
        name="workers",
        version="1.0.0",
        tools=[
            execute_planner_task,
            execute_coder_task,
            execute_reviewer_task,
            execute_tester_task,
            execute_committer_task,
            execute_ideator_task,
            execute_product_manager_task,
            execute_parallel_tasks
        ]
    )

    logger.info("âœ… Worker Tools MCP Server ìƒì„± ì™„ë£Œ (ë³‘ë ¬ ì‹¤í–‰ í¬í•¨)")

    return server

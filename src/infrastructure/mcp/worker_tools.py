"""
Worker Agent Tools - Worker Agentë“¤ì„ Custom Toolë¡œ ë˜í•‘

ê° Worker Agentë¥¼ Claude Agent SDKì˜ Custom Toolë¡œ ë§Œë“¤ì–´,
Manager Agentê°€ í•„ìš”í•  ë•Œ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
"""

from typing import Any, Dict, Callable, Optional, Tuple
from pathlib import Path
import logging
import asyncio
import re
import os
from functools import wraps
from datetime import datetime

from claude_agent_sdk import tool, create_sdk_mcp_server
from claude_agent_sdk.types import ClaudeAgentOptions

from ..claude import WorkerAgent
from domain.models import AgentConfig
from domain.services import MetricsCollector
from ..config import JsonConfigLoader, get_project_root
from ..logging import get_logger, log_exception_silently

logger = get_logger(__name__, component="WorkerTools")


# ë¯¼ê° ì •ë³´ ê²€ì¦ì„ ìœ„í•œ íŒ¨í„´ ì •ì˜
SENSITIVE_FILE_PATTERNS = [
    r"\.env.*",                     # .env, .env.local, .env.production ë“±
    r".*credentials.*",             # credentials.json, aws-credentials ë“±
    r".*secret.*",                  # secret.txt, secrets.yaml ë“±
    r".*\.pem$",                    # SSL ì¸ì¦ì„œ
    r".*\.p12$",                    # PKCS#12 ì¸ì¦ì„œ
    r".*api[_-]?keys?.*",           # api_key.txt, api-keys.json ë“±
    r".*\.key$",                    # ê°œì¸ í‚¤ íŒŒì¼
    r".*private[_-]?key.*",         # private-key.pem ë“±
]

SENSITIVE_CONTENT_PATTERNS = [
    r"api[_-]?key\s*[:=]\s*['\"]?[\w-]{20,}",              # API í‚¤
    r"password\s*[:=]\s*['\"][\w@#$%^&*]+['\"]",          # ë¹„ë°€ë²ˆí˜¸
    r"secret[_-]?key\s*[:=]",                             # Secret í‚¤
    r"aws[_-]?access[_-]?key",                            # AWS Access Key
    r"anthropic[_-]?api[_-]?key",                         # Anthropic API Key
    r"openai[_-]?api[_-]?key",                            # OpenAI API Key
    r"private[_-]?key\s*[:=]",                            # Private Key
    r"bearer\s+[a-zA-Z0-9\-._~+/]+=*",                    # Bearer í† í°
    r"token\s*[:=]\s*['\"]?[\w-]{20,}",                   # ì¼ë°˜ í† í°
]


# ì—ëŸ¬ í†µê³„
_ERROR_STATS = {
    "planner": {"attempts": 0, "failures": 0},
    "coder": {"attempts": 0, "failures": 0},
    "reviewer": {"attempts": 0, "failures": 0},
    "tester": {"attempts": 0, "failures": 0},
    "committer": {"attempts": 0, "failures": 0},
    "ideator": {"attempts": 0, "failures": 0},
    "product_manager": {"attempts": 0, "failures": 0},
    "parallel_executor": {"attempts": 0, "failures": 0}
}

def _get_timeout_from_env(worker_name: str, default: int) -> int:
    """
    í™˜ê²½ë³€ìˆ˜ì—ì„œ íƒ€ì„ì•„ì›ƒ ê°’ ê°€ì ¸ì˜¤ê¸° (ì•ˆì „í•œ int ë³€í™˜)

    Args:
        worker_name: Worker ì´ë¦„ (ì˜ˆ: "planner", "coder")
        default: ê¸°ë³¸ê°’

    Returns:
        íƒ€ì„ì•„ì›ƒ ê°’ (ì´ˆ)
    """
    env_var = f"WORKER_TIMEOUT_{worker_name.upper()}"
    value = os.getenv(env_var)

    if value is None:
        return default

    try:
        return int(value)
    except ValueError:
        logger.warning(
            f"í™˜ê²½ë³€ìˆ˜ {env_var}ì˜ ê°’ '{value}'ì„(ë¥¼) ì •ìˆ˜ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            f"ê¸°ë³¸ê°’ {default}ì´ˆë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )
        return default


# Workerë³„ íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì´ˆ ë‹¨ìœ„, í™˜ê²½ë³€ìˆ˜ > system_config.json > ê¸°ë³¸ê°’ ìˆœ)
# ë‚˜ì¤‘ì— _load_worker_timeouts()ë¡œ ì´ˆê¸°í™”ë¨
_WORKER_TIMEOUTS = {
    "planner": _get_timeout_from_env("planner", 300),
    "coder": _get_timeout_from_env("coder", 600),
    "reviewer": _get_timeout_from_env("reviewer", 300),
    "tester": _get_timeout_from_env("tester", 600),
    "committer": _get_timeout_from_env("committer", 180),
    "ideator": _get_timeout_from_env("ideator", 300),
    "product_manager": _get_timeout_from_env("product_manager", 300),
}


async def retry_with_backoff(
    func: Callable,
    worker_name: str,
    max_retries: int = 3,
    base_delay: float = 1.0
) -> Dict[str, Any]:
    """
    ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ë˜í¼

    Args:
        func: ì‹¤í–‰í•  ë¹„ë™ê¸° í•¨ìˆ˜
        worker_name: Worker ì´ë¦„ (ë¡œê¹…ìš©)
        max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        base_delay: ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

    Returns:
        í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼
    """
    _ERROR_STATS[worker_name]["attempts"] += 1

    for attempt in range(max_retries):
        try:
            result = await func()
            return result

        except Exception as e:
            _ERROR_STATS[worker_name]["failures"] += 1

            if attempt < max_retries - 1:
                # Exponential backoff
                wait_time = base_delay * (2 ** attempt)
                logger.warning(
                    f"âš ï¸  [{worker_name}] ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {e}. "
                    f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„..."
                )
                await asyncio.sleep(wait_time)
            else:
                # ìµœì¢… ì‹¤íŒ¨ - ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë˜ì ¸ì„œ í˜¸ì¶œìê°€ ì²˜ë¦¬í•˜ë„ë¡ í•¨
                logger.error(
                    f"âŒ [{worker_name}] {max_retries}íšŒ ì‹œë„ í›„ ìµœì¢… ì‹¤íŒ¨: {e}"
                )
                raise


# ì „ì—­ ë³€ìˆ˜ë¡œ Worker Agent ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì €ì¥
_WORKER_AGENTS: Dict[str, WorkerAgent] = {}

# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° (ì„ íƒì )
_METRICS_COLLECTOR: Optional[MetricsCollector] = None
_CURRENT_SESSION_ID: Optional[str] = None

# ì›Œí¬í”Œë¡œìš° ì½œë°± (TUIì—ì„œ ì„¤ì •)
_WORKFLOW_CALLBACK: Optional[Callable] = None

# Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± (TUIì—ì„œ ì„¤ì •)
_WORKER_OUTPUT_CALLBACK: Optional[Callable] = None

# Review cycle ì¶”ì  (ë¬´í•œ ë£¨í”„ ë°©ì§€)
_REVIEW_CYCLE_STATE = {
    "count": 0,
    "max_cycles": 3,
    "last_reviewer_call_time": None,
    "coder_called_after_reviewer": False
}


def reset_review_cycle() -> None:
    """
    Review cycleì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    ìƒˆ ì‘ì—… ì‹œì‘ ì‹œ í˜¸ì¶œí•˜ì—¬ ì´ì „ ì‘ì—…ì˜ review countê°€ ëˆ„ì ë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
    """
    global _REVIEW_CYCLE_STATE
    _REVIEW_CYCLE_STATE["count"] = 0
    _REVIEW_CYCLE_STATE["last_reviewer_call_time"] = None
    _REVIEW_CYCLE_STATE["coder_called_after_reviewer"] = False
    logger.info("ğŸ”„ Review cycle has been reset")


def _increment_review_cycle() -> tuple[int, bool]:
    """
    Review cycleì„ ì¦ê°€ì‹œí‚¤ê³  í˜„ì¬ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        tuple[int, bool]: (í˜„ì¬ cycle ìˆ˜, ìµœëŒ€ì¹˜ ì´ˆê³¼ ì—¬ë¶€)
    """
    global _REVIEW_CYCLE_STATE

    _REVIEW_CYCLE_STATE["count"] += 1
    current_cycle = _REVIEW_CYCLE_STATE["count"]
    max_cycles = _REVIEW_CYCLE_STATE["max_cycles"]
    exceeded = current_cycle > max_cycles

    logger.info(
        f"ğŸ”„ Review cycle incremented: {current_cycle}/{max_cycles} "
        f"({'EXCEEDED' if exceeded else 'OK'})"
    )

    return current_cycle, exceeded


def _load_worker_timeouts_from_config():
    """
    system_config.jsonì—ì„œ Worker íƒ€ì„ì•„ì›ƒ ë¡œë“œ

    í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©,
    ì—†ìœ¼ë©´ system_config.json ê°’ ì‚¬ìš©,
    ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
    """
    global _WORKER_TIMEOUTS

    try:
        from ..config import load_system_config

        config = load_system_config()
        timeouts = config.get("timeouts", {})

        # í™˜ê²½ë³€ìˆ˜ > system_config.json > ê¸°ë³¸ê°’ ìˆœìœ¼ë¡œ ìš°ì„ ìˆœìœ„
        _WORKER_TIMEOUTS["planner"] = _get_timeout_from_env(
            "planner", timeouts.get("planner_timeout", 300)
        )
        _WORKER_TIMEOUTS["coder"] = _get_timeout_from_env(
            "coder", timeouts.get("coder_timeout", 600)
        )
        _WORKER_TIMEOUTS["reviewer"] = _get_timeout_from_env(
            "reviewer", timeouts.get("reviewer_timeout", 300)
        )
        _WORKER_TIMEOUTS["tester"] = _get_timeout_from_env(
            "tester", timeouts.get("tester_timeout", 600)
        )
        _WORKER_TIMEOUTS["committer"] = _get_timeout_from_env(
            "committer", timeouts.get("committer_timeout", 180)
        )
        _WORKER_TIMEOUTS["ideator"] = _get_timeout_from_env(
            "ideator", timeouts.get("ideator_timeout", 300)
        )
        _WORKER_TIMEOUTS["product_manager"] = _get_timeout_from_env(
            "product_manager", timeouts.get("product_manager_timeout", 300)
        )

        logger.debug(f"Worker íƒ€ì„ì•„ì›ƒ ì„¤ì • ë¡œë“œ ì™„ë£Œ: {_WORKER_TIMEOUTS}")

    except Exception as e:
        logger.warning(f"system_config.jsonì—ì„œ íƒ€ì„ì•„ì›ƒ ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ê°’ ì‚¬ìš©.")


async def _verify_git_environment() -> Tuple[bool, Optional[str]]:
    """
    Git ì„¤ì¹˜ ë° ì €ì¥ì†Œ í™•ì¸

    Returns:
        (ì„±ê³µ ì—¬ë¶€, ì—ëŸ¬ ë©”ì‹œì§€)
    """
    try:
        # Gitì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        proc = await asyncio.create_subprocess_shell(
            "git --version",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await proc.communicate()

        if proc.returncode != 0:
            return False, "Gitì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."

        # Git ì €ì¥ì†Œì¸ì§€ í™•ì¸
        proc = await asyncio.create_subprocess_shell(
            "git rev-parse --is-inside-work-tree",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await proc.communicate()

        if proc.returncode != 0:
            return False, "í˜„ì¬ ë””ë ‰í† ë¦¬ê°€ Git ì €ì¥ì†Œê°€ ì•„ë‹™ë‹ˆë‹¤."

        return True, None

    except Exception as e:
        logger.error(f"Git í™˜ê²½ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False, f"Git í™˜ê²½ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


async def _validate_commit_safety() -> Tuple[bool, Optional[str]]:
    """
    ì»¤ë°‹ ì•ˆì „ì„± ê²€ì¦ (ë¯¼ê° ì •ë³´ í¬í•¨ ì—¬ë¶€)

    Returns:
        (ì•ˆì „ ì—¬ë¶€, ì—ëŸ¬ ë©”ì‹œì§€)
    """
    try:
        # git status --porcelainìœ¼ë¡œ ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        proc = await asyncio.create_subprocess_shell(
            "git status --porcelain",
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await proc.communicate()

        if proc.returncode != 0:
            return False, f"Git status ì‹¤í–‰ ì‹¤íŒ¨: {stderr.decode('utf-8', errors='ignore')}"

        # ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ íŒŒì‹±
        status_output = stdout.decode("utf-8", errors="ignore")
        changed_files = []

        for line in status_output.splitlines():
            if len(line) < 4:
                continue
            # ìƒíƒœ ì½”ë“œ(2ì) + ê³µë°± + íŒŒì¼ëª…
            file_path = line[3:].strip()
            # -> ë¡œ ë¦¬ë„¤ì„ëœ ê²½ìš° ì²˜ë¦¬
            if " -> " in file_path:
                file_path = file_path.split(" -> ")[1]
            changed_files.append(file_path)

        if not changed_files:
            return False, "ì»¤ë°‹í•  ë³€ê²½ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."

        # 1ë‹¨ê³„: íŒŒì¼ëª… íŒ¨í„´ ê²€ì¦
        sensitive_files = []
        for file_path in changed_files:
            file_name = Path(file_path).name
            for pattern in SENSITIVE_FILE_PATTERNS:
                if re.match(pattern, file_name, re.IGNORECASE):
                    sensitive_files.append(file_path)
                    break

        if sensitive_files:
            files_str = "\n  - ".join(sensitive_files)
            return False, (
                f"ë¯¼ê°í•œ íŒŒì¼ëª…ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤:\n  - {files_str}\n\n"
                "ì´ëŸ¬í•œ íŒŒì¼ì€ ì¼ë°˜ì ìœ¼ë¡œ ì»¤ë°‹í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. "
                "ì •ë§ ì»¤ë°‹í•˜ë ¤ë©´ .gitignoreì— ì¶”ê°€í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ì»¤ë°‹í•˜ì„¸ìš”."
            )

        # 2ë‹¨ê³„: íŒŒì¼ ë‚´ìš© ìŠ¤ìº” (ì •ê·œì‹)
        sensitive_content = []
        for file_path in changed_files:
            # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì´ë‚˜ í° íŒŒì¼ì€ ìŠ¤í‚µ
            try:
                path_obj = Path(file_path)
                if not path_obj.exists():
                    continue

                # íŒŒì¼ í¬ê¸° ì²´í¬ (10MB ì´ìƒì€ ìŠ¤í‚µ)
                if path_obj.stat().st_size > 10 * 1024 * 1024:
                    logger.debug(f"íŒŒì¼ì´ ë„ˆë¬´ í¼, ìŠ¤ìº” ìŠ¤í‚µ: {file_path}")
                    continue

                # í…ìŠ¤íŠ¸ íŒŒì¼ì¸ì§€ í™•ì¸
                with open(path_obj, "rb") as f:
                    chunk = f.read(8192)
                    if b"\x00" in chunk:
                        # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì€ ìŠ¤í‚µ
                        logger.debug(f"ë°”ì´ë„ˆë¦¬ íŒŒì¼, ìŠ¤ìº” ìŠ¤í‚µ: {file_path}")
                        continue

                # íŒŒì¼ ë‚´ìš© ì½ê¸°
                with open(path_obj, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()

                # ë¯¼ê° íŒ¨í„´ ê²€ìƒ‰
                for pattern in SENSITIVE_CONTENT_PATTERNS:
                    matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
                    for match in matches:
                        sensitive_content.append({
                            "file": file_path,
                            "pattern": pattern,
                            "match": match.group()[:50] + "..." if len(match.group()) > 50 else match.group()
                        })
                        break  # íŒŒì¼ë‹¹ í•œ ë²ˆë§Œ ê²½ê³ 

            except Exception as e:
                logger.warning(f"íŒŒì¼ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {file_path} - {e}")
                continue

        if sensitive_content:
            findings = []
            for item in sensitive_content[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                findings.append(f"  - {item['file']}: {item['match']}")
            findings_str = "\n".join(findings)

            if len(sensitive_content) > 5:
                findings_str += f"\n  ... ì™¸ {len(sensitive_content) - 5}ê°œ"

            return False, (
                f"ë¯¼ê°í•œ ì •ë³´ê°€ íŒŒì¼ ë‚´ìš©ì—ì„œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤:\n{findings_str}\n\n"
                "API í‚¤, ë¹„ë°€ë²ˆí˜¸, í† í° ë“±ì€ ì»¤ë°‹í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤. "
                "í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì • íŒŒì¼(.env)ì„ ì‚¬ìš©í•˜ê³  .gitignoreì— ì¶”ê°€í•˜ì„¸ìš”."
            )

        # ëª¨ë“  ê²€ì¦ í†µê³¼
        return True, None

    except Exception as e:
        logger.error(f"ì»¤ë°‹ ì•ˆì „ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        # ê²€ì¦ ì‹¤íŒ¨ ì‹œ False Positive ë°©ì§€ë¥¼ ìœ„í•´ ê²½ê³ ë§Œ í‘œì‹œ
        return True, None


def initialize_workers(config_path: Path):
    """
    Worker Agentë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        config_path: Agent ì„¤ì • íŒŒì¼ ê²½ë¡œ
    """
    global _WORKER_AGENTS, _REVIEW_CYCLE_STATE

    # system_config.jsonì—ì„œ íƒ€ì„ì•„ì›ƒ ì„¤ì • ë¡œë“œ
    _load_worker_timeouts_from_config()

    # system_config.jsonì—ì„œ max_review_iterations ë¡œë“œ
    try:
        from ..config import load_system_config
        config = load_system_config()
        _REVIEW_CYCLE_STATE["max_cycles"] = config.get("workflow_limits", {}).get(
            "max_review_iterations", 3
        )
        logger.info(
            f"âœ… Review cycle ìµœëŒ€ íšŸìˆ˜: {_REVIEW_CYCLE_STATE['max_cycles']}íšŒ"
        )
    except Exception as e:
        logger.warning(f"max_review_iterations ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ê°’ 3 ì‚¬ìš©.")
        _REVIEW_CYCLE_STATE["max_cycles"] = 3

    loader = JsonConfigLoader(get_project_root())
    worker_configs = loader.load_agent_configs()

    for config in worker_configs:
        worker = WorkerAgent(config)
        _WORKER_AGENTS[config.name] = worker
        logger.info(
            "Worker agent initialized",
            worker_name=config.name,
            role=config.role,
            model=config.model
        )


def set_metrics_collector(collector: MetricsCollector, session_id: str) -> None:
    """
    ë©”íŠ¸ë¦­ ì»¬ë ‰í„° ì„¤ì • (TUI/CLIì—ì„œ í˜¸ì¶œ)

    Args:
        collector: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°
        session_id: í˜„ì¬ ì„¸ì…˜ ID
    """
    global _METRICS_COLLECTOR, _CURRENT_SESSION_ID
    _METRICS_COLLECTOR = collector
    _CURRENT_SESSION_ID = session_id
    logger.info("Metrics collector configured", session_id=session_id)


def update_session_id(session_id: str) -> None:
    """
    í˜„ì¬ ì„¸ì…˜ ID ì—…ë°ì´íŠ¸

    Args:
        session_id: ìƒˆ ì„¸ì…˜ ID
    """
    global _CURRENT_SESSION_ID
    _CURRENT_SESSION_ID = session_id
    logger.info("Session ID updated", session_id=session_id)


def set_workflow_callback(callback: Optional[Callable]) -> None:
    """
    ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì—…ë°ì´íŠ¸ ì½œë°± ì„¤ì •

    Args:
        callback: ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
                  ì‹œê·¸ë‹ˆì²˜: callback(worker_name: str, status: str, error: Optional[str])
    """
    global _WORKFLOW_CALLBACK
    _WORKFLOW_CALLBACK = callback
    logger.info("âœ… ì›Œí¬í”Œë¡œìš° ì½œë°± ì„¤ì • ì™„ë£Œ")


def set_worker_output_callback(callback: Optional[Callable]) -> None:
    """
    Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •

    Args:
        callback: Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
                  ì‹œê·¸ë‹ˆì²˜: callback(worker_name: str, chunk: str)
    """
    global _WORKER_OUTPUT_CALLBACK
    _WORKER_OUTPUT_CALLBACK = callback
    logger.info("âœ… Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì • ì™„ë£Œ")


def worker_tool(
    worker_name: str,
    description: str,
    retry: bool = False,
    security_check: bool = False
) -> Callable:
    """
    Worker Tool ë°ì½”ë ˆì´í„° íŒ©í† ë¦¬

    ê³µí†µ ë¡œì§ì„ ë°ì½”ë ˆì´í„°ë¡œ ì¶”ì¶œí•˜ì—¬ ì½”ë“œ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.

    Args:
        worker_name: Worker ì´ë¦„ (ì˜ˆ: "planner", "coder")
        description: Tool ì„¤ëª…
        retry: ì¬ì‹œë„ ë¡œì§ ì‚¬ìš© ì—¬ë¶€
        security_check: ë³´ì•ˆ ê²€ì¦ ìˆ˜í–‰ ì—¬ë¶€ (Committer ì „ìš©)

    Returns:
        ë°ì½”ë ˆì´í„° í•¨ìˆ˜

    Example:
        @worker_tool("planner", "ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½", retry=True)
        async def execute_planner_task(args: Dict[str, Any]) -> Dict[str, Any]:
            pass
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(args: Dict[str, Any]) -> Dict[str, Any]:
            """
            Worker Tool ë˜í¼ í•¨ìˆ˜

            Args:
                args: {"task_description": "ì‘ì—… ì„¤ëª…"}

            Returns:
                Agent ì‹¤í–‰ ê²°ê³¼
            """
            # Committerì˜ ê²½ìš° ë³´ì•ˆ ê²€ì¦ ìˆ˜í–‰
            if security_check:
                logger.debug(
                    f"[{worker_name.capitalize()} Tool] ì‘ì—… ì‹¤í–‰ ì‹œì‘: "
                    f"{args['task_description'][:50]}..."
                )

                # 1ë‹¨ê³„: Git í™˜ê²½ ê²€ì¦
                is_valid, error_msg = await _verify_git_environment()
                if not is_valid:
                    logger.error(f"[{worker_name.capitalize()} Tool] Git í™˜ê²½ ì˜¤ë¥˜: {error_msg}")
                    return {
                        "content": [
                            {"type": "text", "text": f"âŒ Git í™˜ê²½ ì˜¤ë¥˜: {error_msg}"}
                        ]
                    }

                # 2ë‹¨ê³„: ë¯¼ê° ì •ë³´ ê²€ì¦
                is_safe, error_msg = await _validate_commit_safety()
                if not is_safe:
                    logger.warning(
                        f"[{worker_name.capitalize()} Tool] ì»¤ë°‹ ê±°ë¶€ (ë¯¼ê° ì •ë³´ ê°ì§€): {error_msg}"
                    )
                    return {
                        "content": [
                            {
                                "type": "text",
                                "text": f"âŒ ì»¤ë°‹ ê±°ë¶€ (ë³´ì•ˆ ê²€ì¦ ì‹¤íŒ¨):\n\n{error_msg}"
                            }
                        ]
                    }

                logger.info(
                    f"[{worker_name.capitalize()} Tool] ë³´ì•ˆ ê²€ì¦ í†µê³¼ - "
                    f"{worker_name.capitalize()} Agent ì‹¤í–‰"
                )

            # ê³µí†µ ì‹¤í–‰ ë¡œì§
            return await _execute_worker_task(
                worker_name,
                args["task_description"],
                use_retry=retry
            )

        # @tool ë°ì½”ë ˆì´í„° ì ìš©
        return tool(
            f"execute_{worker_name}_task",
            f"{worker_name.capitalize()} Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. {description}",
            {
                "task_description": {
                    "type": "string",
                    "description": "ì‘ì—… ì„¤ëª…"
                }
            }
        )(wrapper)

    return decorator


async def _execute_worker_task(
    worker_name: str,
    task_description: str,
    use_retry: bool = False
) -> Dict[str, Any]:
    """
    Worker Agent ì‹¤í–‰ ê³µí†µ ë¡œì§ (íƒ€ì„ì•„ì›ƒ ì ìš© + Review cycle ì¶”ì )

    Args:
        worker_name: Worker ì´ë¦„ (ì˜ˆ: "planner", "coder")
        task_description: ì‘ì—… ì„¤ëª…
        use_retry: ì¬ì‹œë„ ë¡œì§ ì‚¬ìš© ì—¬ë¶€

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    global _REVIEW_CYCLE_STATE

    # Worker ì „ìš© ë¡œê±° ìƒì„± (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
    worker_logger = get_logger(__name__, worker_name=worker_name, component="WorkerExecution")
    worker_logger.debug(
        "Task execution started",
        task_description=task_description[:100]
    )

    worker = _WORKER_AGENTS.get(worker_name)
    if not worker:
        worker_logger.error("Worker agent not found")
        return {
            "content": [
                {"type": "text", "text": f"âŒ {worker_name.capitalize()} Agentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            ]
        }

    # ìƒˆ ì‘ì—… ì‹œì‘ ì‹œ Review cycle ì´ˆê¸°í™” (Planner ë˜ëŠ” Coder ì‹œì‘ ì‹œ)
    if worker_name in ["planner", "coder"]:
        # PlannerëŠ” í•­ìƒ ìƒˆ ì‘ì—…ì˜ ì‹œì‘ì´ë¯€ë¡œ ë¬´ì¡°ê±´ ì´ˆê¸°í™”
        # CoderëŠ” Reviewer í˜¸ì¶œ ì´í›„ê°€ ì•„ë‹ˆë©´ ìƒˆ ì‘ì—…ì˜ ì‹œì‘ìœ¼ë¡œ ê°„ì£¼
        if worker_name == "planner" or not _REVIEW_CYCLE_STATE["coder_called_after_reviewer"]:
            reset_review_cycle()

    # Review cycle ì¶”ì  ë¡œì§ (ë¬´í•œ ë£¨í”„ ë°©ì§€)

    if worker_name == "reviewer":
        # Reviewer í˜¸ì¶œ ì‹œ cycle count ì¦ê°€ (Coder í˜¸ì¶œ í›„ì¸ ê²½ìš°)
        if _REVIEW_CYCLE_STATE["coder_called_after_reviewer"]:
            _REVIEW_CYCLE_STATE["coder_called_after_reviewer"] = False
            # Cycle count ì¦ê°€ ë° ìµœëŒ€ì¹˜ ì²´í¬
            current_cycle, exceeded = _increment_review_cycle()

            # ìµœëŒ€ íšŸìˆ˜ ì´ˆê³¼ ì²´í¬
            if exceeded:
                error_msg = (
                    f"âš ï¸  Review Cycleì´ ìµœëŒ€ íšŸìˆ˜ "
                    f"({_REVIEW_CYCLE_STATE['max_cycles']}íšŒ)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\n\n"
                    f"ë¬´í•œ ë£¨í”„ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ Reviewer ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n"
                    f"ìˆ˜ë™ìœ¼ë¡œ ì½”ë“œë¥¼ ê²€í† í•˜ê³  ìˆ˜ì •í•˜ê±°ë‚˜, ìš”êµ¬ì‚¬í•­ì„ ì¡°ì •í•´ì£¼ì„¸ìš”.\n\n"
                    f"(Tip: system_config.jsonì˜ 'workflow_limits.max_review_iterations'ë¡œ "
                    f"ìµœëŒ€ íšŸìˆ˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"
                )
                logger.error(error_msg)

                # Review cycle ì´ˆê¸°í™”
                reset_review_cycle()

                return {
                    "content": [{"type": "text", "text": error_msg}]
                }

        _REVIEW_CYCLE_STATE["last_reviewer_call_time"] = datetime.now()

    elif worker_name == "coder":
        # Reviewer í˜¸ì¶œ í›„ Coderê°€ í˜¸ì¶œë˜ë©´ í”Œë˜ê·¸ ì„¤ì •
        if _REVIEW_CYCLE_STATE["last_reviewer_call_time"] is not None:
            _REVIEW_CYCLE_STATE["coder_called_after_reviewer"] = True
            logger.debug("Reviewer í˜¸ì¶œ í›„ Coder ì‹¤í–‰ ê°ì§€ (ë‹¤ìŒ Reviewer í˜¸ì¶œ ì‹œ cycle count ì¦ê°€)")

    # íƒ€ì„ì•„ì›ƒ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    timeout = _WORKER_TIMEOUTS.get(worker_name, 300)
    worker_logger.debug("Timeout configured", timeout_seconds=timeout)

    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘
    start_time = datetime.now()
    success = False
    error_message = None

    # ì›Œí¬í”Œë¡œìš° ì½œë°±: RUNNING ìƒíƒœ
    if _WORKFLOW_CALLBACK:
        try:
            _WORKFLOW_CALLBACK(worker_name, "running", None)
        except Exception as e:
            logger.warning(f"ì›Œí¬í”Œë¡œìš° ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨ (running): {e}")

    async def execute():
        result = ""
        async for chunk in worker.execute_task(task_description):
            result += chunk
            # Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í˜¸ì¶œ
            if _WORKER_OUTPUT_CALLBACK:
                try:
                    _WORKER_OUTPUT_CALLBACK(worker_name, chunk)
                except Exception as e:
                    logger.warning(f"Worker ì¶œë ¥ ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return {"content": [{"type": "text", "text": result}]}

    try:
        # íƒ€ì„ì•„ì›ƒ ì ìš©
        if use_retry:
            result = await asyncio.wait_for(
                retry_with_backoff(execute, worker_name),
                timeout=timeout
            )
        else:
            _ERROR_STATS[worker_name]["attempts"] += 1
            result = await asyncio.wait_for(execute(), timeout=timeout)

        success = True

        # ì›Œí¬í”Œë¡œìš° ì½œë°±: COMPLETED ìƒíƒœ
        if _WORKFLOW_CALLBACK:
            try:
                _WORKFLOW_CALLBACK(worker_name, "completed", None)
            except Exception as e:
                logger.warning(f"ì›Œí¬í”Œë¡œìš° ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨ (completed): {e}")

        return result

    except asyncio.TimeoutError:
        _ERROR_STATS[worker_name]["failures"] += 1
        error_message = f"íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ ì´ˆê³¼)"
        worker_logger.error(
            "Task execution timeout",
            timeout_seconds=timeout,
            exc_info=True
        )

        # ì›Œí¬í”Œë¡œìš° ì½œë°±: FAILED ìƒíƒœ
        if _WORKFLOW_CALLBACK:
            try:
                _WORKFLOW_CALLBACK(worker_name, "failed", error_message)
            except Exception as callback_error:
                logger.warning(f"ì›Œí¬í”Œë¡œìš° ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨ (failed): {callback_error}")

        return {
            "content": [
                {
                    "type": "text",
                    "text": (
                        f"âŒ {worker_name.capitalize()} ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ\n\n"
                        f"ì‘ì—…ì´ {timeout}ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                        f"í™˜ê²½ë³€ìˆ˜ WORKER_TIMEOUT_{worker_name.upper()}ë¥¼ "
                        f"ì¡°ì •í•˜ì—¬ íƒ€ì„ì•„ì›ƒì„ ëŠ˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    )
                }
            ]
        }

    except Exception as e:
        _ERROR_STATS[worker_name]["failures"] += 1
        error_message = str(e)

        # ëŸ°íƒ€ì„ ì—ëŸ¬ë¥¼ ì¡°ìš©íˆ ë¡œê·¸ì— ê¸°ë¡ (í”„ë¡œê·¸ë¨ ì¢…ë£Œí•˜ì§€ ì•ŠìŒ)
        log_exception_silently(
            worker_logger,
            e,
            f"Worker Tool ({worker_name}) execution failed",
            worker_name=worker_name,
            task_description=task_description[:100]
        )

        # ì›Œí¬í”Œë¡œìš° ì½œë°±: FAILED ìƒíƒœ
        if _WORKFLOW_CALLBACK:
            try:
                _WORKFLOW_CALLBACK(worker_name, "failed", str(e))
            except Exception as callback_error:
                logger.warning(f"ì›Œí¬í”Œë¡œìš° ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨ (failed): {callback_error}")

        return {
            "content": [
                {
                    "type": "text",
                    "text": (
                        f"âŒ {worker_name.capitalize()} ì‹¤í–‰ ì‹¤íŒ¨\n\n"
                        f"ì—ëŸ¬: {e}\n\n"
                        f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ëŠ” ì—ëŸ¬ ë¡œê·¸ (~/.better-llm/{{project}}/logs/better-llm-error.log)ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    )
                }
            ]
        }

    finally:
        # ë©”íŠ¸ë¦­ ê¸°ë¡ (ì»¬ë ‰í„°ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´)
        if _METRICS_COLLECTOR and _CURRENT_SESSION_ID:
            end_time = datetime.now()
            try:
                _METRICS_COLLECTOR.record_worker_execution(
                    session_id=_CURRENT_SESSION_ID,
                    worker_name=worker_name,
                    task_description=task_description[:100],  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„
                    start_time=start_time,
                    end_time=end_time,
                    success=success,
                    tokens_used=None,  # ì¶”í›„ Claude SDKì—ì„œ í† í° ì •ë³´ ê°€ì ¸ì˜¤ë©´ ì¶”ê°€
                    error_message=error_message,
                )
            except Exception as metrics_error:
                # ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ë¬´ì‹œ
                logger.warning(f"ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {metrics_error}")


@worker_tool("planner", "ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.", retry=True)
async def execute_planner_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Planner Agent ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    pass  # ë°ì½”ë ˆì´í„°ê°€ ëª¨ë“  ë¡œì§ì„ ì²˜ë¦¬


@worker_tool("coder", "ì½”ë“œ ì‘ì„±, ìˆ˜ì •, ë¦¬íŒ©í† ë§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.", retry=False)
async def execute_coder_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Coder Agent ì‹¤í–‰

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    pass  # ë°ì½”ë ˆì´í„°ê°€ ëª¨ë“  ë¡œì§ì„ ì²˜ë¦¬


@worker_tool("tester", "í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ì‹¤í–‰ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.", retry=False)
async def execute_tester_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Tester Agent ì‹¤í–‰

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    pass  # ë°ì½”ë ˆì´í„°ê°€ ëª¨ë“  ë¡œì§ì„ ì²˜ë¦¬


@worker_tool("reviewer", "ì½”ë“œ ë¦¬ë·° ë° í’ˆì§ˆ ê²€ì¦ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.", retry=False)
async def execute_reviewer_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Reviewer Agentì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì½”ë“œ ë¦¬ë·° ë° í’ˆì§ˆ ê²€ì¦ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.

    Review cycleì€ ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•´ ìµœëŒ€ íšŸìˆ˜ê°€ ì œí•œë©ë‹ˆë‹¤.
    (ê¸°ë³¸ê°’: 3íšŒ, system_config.jsonì˜ 'workflow_limits.max_review_iterations'ë¡œ ì¡°ì • ê°€ëŠ¥)

    Args:
        args: {"task_description": "ë¦¬ë·° ìš”ì²­ ë‚´ìš©"}
              - task_description: ë¦¬ë·° ëŒ€ìƒ ë° ìš”ì²­ ì‚¬í•­
              - (í–¥í›„ í™•ì¥ ê°€ëŠ¥) context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
              - (í–¥í›„ í™•ì¥ ê°€ëŠ¥) severity_threshold: ìµœì†Œ ë³´ê³  ì‹¬ê°ë„

    Returns:
        Dict[str, Any]: Agent ì‹¤í–‰ ê²°ê³¼
            - content: [{"type": "text", "text": "ë¦¬ë·° ê²°ê³¼"}]

    Raises:
        Exception: Review cycleì´ ìµœëŒ€ì¹˜ë¥¼ ì´ˆê³¼í•œ ê²½ìš°

    Note:
        - Review cycleì€ Reviewer â†’ Coder â†’ Reviewer íŒ¨í„´ì„ ê°ì§€í•˜ì—¬ ì¦ê°€í•©ë‹ˆë‹¤.
        - ìµœëŒ€ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ ì‹¤í–‰ì´ ì¤‘ë‹¨ë˜ë©°, ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
        - ìƒˆ ì‘ì—… ì‹œì‘ ì‹œ(Planner ë˜ëŠ” Coder í˜¸ì¶œ) Review cycleì´ ìë™ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
    """
    pass  # ë°ì½”ë ˆì´í„°ê°€ ëª¨ë“  ë¡œì§ì„ ì²˜ë¦¬


@worker_tool("committer", "Git ì»¤ë°‹ ìƒì„±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.", retry=False, security_check=True)
async def execute_committer_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Committer Agent ì‹¤í–‰ (ë³´ì•ˆ ê²€ì¦ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    pass  # ë°ì½”ë ˆì´í„°ê°€ ëª¨ë“  ë¡œì§ì„ ì²˜ë¦¬ (ë³´ì•ˆ ê²€ì¦ í¬í•¨)


@worker_tool("ideator", "ì°½ì˜ì  ì•„ì´ë””ì–´ ìƒì„± ë° ë¸Œë ˆì¸ìŠ¤í† ë°ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.", retry=True)
async def execute_ideator_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Ideator Agent ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    pass  # ë°ì½”ë ˆì´í„°ê°€ ëª¨ë“  ë¡œì§ì„ ì²˜ë¦¬


@worker_tool("product_manager", "ì œí’ˆ ê¸°íš ë° ìš”êµ¬ì‚¬í•­ ì •ì˜ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.", retry=True)
async def execute_product_manager_task(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    Product Manager Agent ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)

    Args:
        args: {"task_description": "ì‘ì—… ì„¤ëª…"}

    Returns:
        Agent ì‹¤í–‰ ê²°ê³¼
    """
    pass  # ë°ì½”ë ˆì´í„°ê°€ ëª¨ë“  ë¡œì§ì„ ì²˜ë¦¬


@tool(
    "execute_parallel_tasks",
    "ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSONì„ ë°›ì•„ì„œ Taskë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.",
    {
        "plan_json": {
            "type": "string",
            "description": "Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSON ë¬¸ìì—´"
        }
    }
)
async def execute_parallel_tasks(args: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ Tool

    Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSONì„ ë°›ì•„ì„œ
    ParallelTaskExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ Taskë“¤ì„ ë³‘ë ¬ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Args:
        args: {
            "plan_json": "Plannerê°€ ìƒì„±í•œ ë³‘ë ¬ ì‹¤í–‰ ê³„íš JSON ë¬¸ìì—´"
        }

    Returns:
        {
            "content": [{"type": "text", "text": "ì‹¤í–‰ ê²°ê³¼"}],
            "success": True/False,
            "metadata": {
                "completed_tasks": int,
                "failed_tasks": int,
                "total_duration": float,
                "speedup_factor": float
            }
        }
    """
    from domain.models.parallel_task import TaskExecutionPlan, ParallelTask
    from domain.services.parallel_executor import ParallelTaskExecutor
    import json
    import re

    worker_name = "parallel_executor"
    _record_attempt(worker_name)

    try:
        # ì¸ì ê²€ì¦
        if "plan_json" not in args:
            raise ValueError("plan_json ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤")

        plan_json_raw = args["plan_json"]

        # JSON ì¶”ì¶œ (```json ... ``` ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        json_match = re.search(r'```json\s*(.*?)\s*```', plan_json_raw, re.DOTALL)
        if json_match:
            plan_json = json_match.group(1).strip()
        else:
            plan_json = plan_json_raw.strip()

        logger.info(f"[{worker_name}] ë³‘ë ¬ ì‹¤í–‰ ê³„íš íŒŒì‹± ì‹œì‘")

        # TaskExecutionPlan ìƒì„±
        try:
            plan = TaskExecutionPlan.from_json(plan_json)
        except ValueError as e:
            raise ValueError(f"ë³‘ë ¬ ì‹¤í–‰ ê³„íš íŒŒì‹± ì‹¤íŒ¨: {e}")

        logger.info(
            f"[{worker_name}] {len(plan.tasks)}ê°œ Task ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘",
            task_ids=[task.id for task in plan.tasks]
        )

        # Coder Workerë¥¼ task_executorë¡œ ë˜í•‘
        async def coder_task_executor(task: ParallelTask) -> str:
            """ë‹¨ì¼ Task ì‹¤í–‰ (Coder Worker í˜¸ì¶œ)"""
            coder_agent = _WORKER_AGENTS.get("coder")
            if not coder_agent:
                raise RuntimeError("Coder Agentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # Coderì—ê²Œ ì „ë‹¬í•  ì‘ì—… ì„¤ëª…
            # Task descriptionì— target_files ì •ë³´ ì¶”ê°€
            task_description = task.description
            if task.target_files:
                task_description += f"\n\n**Target Files**: {', '.join(task.target_files)}"

            result = ""
            async for chunk in coder_agent.execute_task(task_description):
                result += chunk

            return result

        # ParallelTaskExecutor ìƒì„± ë° ì‹¤í–‰
        executor = ParallelTaskExecutor(
            task_executor=coder_task_executor,
            max_concurrent_tasks=5  # ë™ì‹œ ì‹¤í–‰ ìµœëŒ€ 5ê°œ
        )

        execution_result = await executor.execute(plan)

        # ê²°ê³¼ í¬ë§·íŒ…
        result_lines = []
        result_lines.append(f"ğŸš€ ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ\n")
        result_lines.append(f"ğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
        result_lines.append(f"   - ì„±ê³µ: {len(execution_result.completed_tasks)}ê°œ")
        result_lines.append(f"   - ì‹¤íŒ¨: {len(execution_result.failed_tasks)}ê°œ")
        result_lines.append(f"   - ì‹¤í–‰ ì‹œê°„: {execution_result.total_duration:.1f}ì´ˆ")
        result_lines.append(f"   - ì†ë„ í–¥ìƒ: {execution_result.speedup_factor:.2f}x")
        result_lines.append(f"   - ì„±ê³µë¥ : {execution_result.success_rate * 100:.0f}%\n")

        # ì™„ë£Œëœ Task ìƒì„¸
        if execution_result.completed_tasks:
            result_lines.append("âœ… ì™„ë£Œëœ Task:")
            for task in execution_result.completed_tasks:
                result_lines.append(f"   - [{task.id}] {task.description}")
                result_lines.append(f"     íŒŒì¼: {', '.join(task.target_files)}")
                if task.duration_seconds():
                    result_lines.append(f"     ì‹¤í–‰ ì‹œê°„: {task.duration_seconds():.1f}ì´ˆ")
                result_lines.append("")

        # ì‹¤íŒ¨í•œ Task ìƒì„¸
        if execution_result.failed_tasks:
            result_lines.append("âŒ ì‹¤íŒ¨í•œ Task:")
            for task in execution_result.failed_tasks:
                result_lines.append(f"   - [{task.id}] {task.description}")
                result_lines.append(f"     ì—ëŸ¬: {task.error}")
                result_lines.append("")

        # í†µí•© ì£¼ì˜ì‚¬í•­
        if plan.integration_notes:
            result_lines.append(f"ğŸ“ í†µí•© ì‹œ ì£¼ì˜ì‚¬í•­:")
            result_lines.append(f"   {plan.integration_notes}\n")

        result_text = "\n".join(result_lines)

        logger.info(
            f"[{worker_name}] ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ",
            completed=len(execution_result.completed_tasks),
            failed=len(execution_result.failed_tasks),
            duration=execution_result.total_duration
        )

        return {
            "content": [{"type": "text", "text": result_text}],
            "success": execution_result.all_succeeded,
            "metadata": {
                "completed_tasks": len(execution_result.completed_tasks),
                "failed_tasks": len(execution_result.failed_tasks),
                "total_duration": execution_result.total_duration,
                "speedup_factor": execution_result.speedup_factor,
                "success_rate": execution_result.success_rate
            }
        }

    except Exception as e:
        _record_failure(worker_name)
        logger.error(f"[{worker_name}] ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        return {
            "content": [{"type": "text", "text": f"âŒ ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}"}],
            "success": False,
            "error": str(e)
        }


def get_error_statistics() -> Dict[str, Any]:
    """
    ì—ëŸ¬ í†µê³„ ì¡°íšŒ

    Returns:
        ê° Workerì˜ ì‹œë„/ì‹¤íŒ¨ í†µê³„ ë° ì—ëŸ¬ìœ¨
    """
    stats = {}
    for worker_name, data in _ERROR_STATS.items():
        attempts = data["attempts"]
        failures = data["failures"]
        error_rate = (failures / attempts * 100) if attempts > 0 else 0.0

        stats[worker_name] = {
            "attempts": attempts,
            "failures": failures,
            "successes": attempts - failures,
            "error_rate": round(error_rate, 2)
        }

    return stats


def reset_error_statistics():
    """
    ì—ëŸ¬ í†µê³„ ì´ˆê¸°í™”
    """
    global _ERROR_STATS
    for worker_name in _ERROR_STATS:
        _ERROR_STATS[worker_name]["attempts"] = 0
        _ERROR_STATS[worker_name]["failures"] = 0
    logger.info("âœ… ì—ëŸ¬ í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")


def log_error_summary():
    """
    ì—ëŸ¬ í†µê³„ ìš”ì•½ ë¡œê·¸ ì¶œë ¥
    """
    stats = get_error_statistics()
    logger.info("=" * 60)
    logger.info("ğŸ“Š Worker Tools ì—ëŸ¬ í†µê³„")
    logger.info("=" * 60)

    for worker_name, data in stats.items():
        logger.info(
            f"[{worker_name.upper()}] "
            f"ì‹œë„: {data['attempts']}, "
            f"ì„±ê³µ: {data['successes']}, "
            f"ì‹¤íŒ¨: {data['failures']}, "
            f"ì—ëŸ¬ìœ¨: {data['error_rate']}%"
        )

    logger.info("=" * 60)


def create_worker_tools_server():
    """
    Worker Toolë“¤ì„ í¬í•¨í•˜ëŠ” MCP ì„œë²„ ìƒì„±

    Returns:
        MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤
    """
    server = create_sdk_mcp_server(
        name="workers",
        version="1.0.0",
        tools=[
            execute_planner_task,
            execute_coder_task,
            execute_reviewer_task,
            execute_tester_task,
            execute_committer_task,
            execute_ideator_task,
            execute_product_manager_task,
            execute_parallel_tasks  # ë³‘ë ¬ ì‹¤í–‰ Tool
        ]
    )

    logger.info("âœ… Worker Tools MCP Server ìƒì„± ì™„ë£Œ (ë³‘ë ¬ ì‹¤í–‰ í¬í•¨)")

    return server

"""
Worker Executor - Worker ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” í†µí•© Executor

Level 1ì˜ 4ê°œ ë§¤ë‹ˆì €ë¥¼ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ Worker ì‹¤í–‰ ë¡œì§ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.
- ReviewCycleManager: Review cycle ì¶”ì 
- CommitSafetyValidator: Commit ì•ˆì „ì„± ê²€ì¦
- WorkflowCallbackHandler: ì›Œí¬í”Œë¡œìš° ì½œë°± ê´€ë¦¬
- ErrorStatisticsManager: ì—ëŸ¬ í†µê³„ ìˆ˜ì§‘
"""

from dataclasses import dataclass, field
from typing import Any, Dict, Callable, Optional
from datetime import datetime
import asyncio
import logging
import re
import os

from src.infrastructure.mcp.review_cycle_manager import ReviewCycleManager
from src.infrastructure.mcp.commit_validator import CommitSafetyValidator
from src.infrastructure.mcp.workflow_callback_handler import (
    WorkflowCallbackHandler,
    WorkflowEventType
)
from src.infrastructure.mcp.error_statistics_manager import ErrorStatisticsManager
from src.infrastructure.mcp.context_metadata_formatter import ContextMetadataFormatter
from src.infrastructure.mcp.output_summarizer import WorkerOutputSummarizer
from src.infrastructure.logging import get_logger, log_exception_silently

logger = get_logger(__name__, component="WorkerExecutor")

# í™˜ê²½ë³€ìˆ˜ë¡œ Worker ì¶œë ¥ ìš”ì•½ ê¸°ëŠ¥ ì œì–´
ENABLE_WORKER_OUTPUT_SUMMARY = os.getenv("DISABLE_WORKER_OUTPUT_SUMMARY", "false").lower() != "true"


@dataclass
class WorkerExecutionContext:
    """
    Worker ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

    Worker ì‹¤í–‰ì— í•„ìš”í•œ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

    Attributes:
        worker_name: Worker ì´ë¦„ (ì˜ˆ: "planner", "coder", "reviewer")
        task_description: ì‘ì—… ì„¤ëª…
        use_retry: ì¬ì‹œë„ ë¡œì§ ì‚¬ìš© ì—¬ë¶€
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        session_id: í˜„ì¬ ì„¸ì…˜ ID (ë©”íŠ¸ë¦­ ìˆ˜ì§‘ìš©)
        metrics_collector: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° (ì„ íƒì )
        worker_agent: Worker Agent ì¸ìŠ¤í„´ìŠ¤
        worker_output_callback: Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± (ì„ íƒì )
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

    Example:
        >>> context = WorkerExecutionContext(
        ...     worker_name="coder",
        ...     task_description="Implement feature X",
        ...     timeout=600,
        ...     worker_agent=coder_agent
        ... )
        >>> executor = WorkerExecutor()
        >>> result = await executor.execute(context)
    """
    worker_name: str
    task_description: str
    use_retry: bool = False
    timeout: int = 600
    session_id: Optional[str] = None
    metrics_collector: Optional[Any] = None
    worker_agent: Optional[Any] = None
    worker_output_callback: Optional[Callable[[str, str], None]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """
        ì»¨í…ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ì§ë ¬í™” ê°€ëŠ¥)

        Returns:
            ì§ë ¬í™” ê°€ëŠ¥í•œ ë”•ì…”ë„ˆë¦¬
        """
        return {
            "worker_name": self.worker_name,
            "task_description": self.task_description[:100],  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„
            "use_retry": self.use_retry,
            "timeout": self.timeout,
            "session_id": self.session_id,
            "metadata": self.metadata
        }


class WorkerExecutor:
    """
    Worker ì‹¤í–‰ì„ ê´€ë¦¬í•˜ëŠ” í†µí•© Executor

    Level 1ì˜ 4ê°œ ë§¤ë‹ˆì €ë¥¼ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ ì‹¤í–‰ ë¡œì§ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.
    ê¸°ì¡´ `_execute_worker_task()` í•¨ìˆ˜ (208ì¤„, 5ì¤‘ try-except)ë¥¼
    êµ¬ì¡°í™”ëœ í´ë˜ìŠ¤ë¡œ ë¦¬íŒ©í† ë§í•˜ì—¬ ë³µì¡ë„ë¥¼ ë‚®ì¶¥ë‹ˆë‹¤.

    Attributes:
        review_manager: Review cycle ì¶”ì  ê´€ë¦¬ì
        commit_validator: Commit ì•ˆì „ì„± ê²€ì¦ê¸°
        callback_handler: ì›Œí¬í”Œë¡œìš° ì½œë°± í•¸ë“¤ëŸ¬
        error_manager: ì—ëŸ¬ í†µê³„ ê´€ë¦¬ì

    Example:
        >>> executor = WorkerExecutor()
        >>> context = WorkerExecutionContext(
        ...     worker_name="coder",
        ...     task_description="Refactor module X",
        ...     worker_agent=coder_agent,
        ...     timeout=600
        ... )
        >>> result = await executor.execute(context)
        >>> print(result["content"][0]["text"])
    """

    def __init__(
        self,
        review_manager: Optional[ReviewCycleManager] = None,
        commit_validator: Optional[CommitSafetyValidator] = None,
        callback_handler: Optional[WorkflowCallbackHandler] = None,
        error_manager: Optional[ErrorStatisticsManager] = None,
        metadata_formatter: Optional[ContextMetadataFormatter] = None,
        output_summarizer: Optional[WorkerOutputSummarizer] = None
    ):
        """
        WorkerExecutor ì´ˆê¸°í™”

        Args:
            review_manager: Review cycle ì¶”ì  ê´€ë¦¬ì (ê¸°ë³¸ê°’: ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
            commit_validator: Commit ì•ˆì „ì„± ê²€ì¦ê¸° (ê¸°ë³¸ê°’: ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
            callback_handler: ì›Œí¬í”Œë¡œìš° ì½œë°± í•¸ë“¤ëŸ¬ (ê¸°ë³¸ê°’: ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
            error_manager: ì—ëŸ¬ í†µê³„ ê´€ë¦¬ì (ê¸°ë³¸ê°’: ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
            metadata_formatter: ì»¨í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° í¬ë§·í„° (ê¸°ë³¸ê°’: ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
            output_summarizer: Worker ì¶œë ¥ ìš”ì•½ê¸° (ê¸°ë³¸ê°’: ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)
        """
        self.review_manager = review_manager or ReviewCycleManager()
        self.commit_validator = commit_validator or CommitSafetyValidator()
        self.callback_handler = callback_handler or WorkflowCallbackHandler()
        self.error_manager = error_manager or ErrorStatisticsManager()
        self.metadata_formatter = metadata_formatter or ContextMetadataFormatter()
        self.output_summarizer = output_summarizer or WorkerOutputSummarizer()

        # Context metadata í™œì„±í™” ì—¬ë¶€ (system_config.jsonì—ì„œ ë¡œë“œ)
        self.context_metadata_enabled = self._load_context_metadata_config()

        # Worker ì¶œë ¥ ìš”ì•½ í™œì„±í™” ì—¬ë¶€
        self.output_summary_enabled = ENABLE_WORKER_OUTPUT_SUMMARY

        logger.info(
            "WorkerExecutor initialized",
            context_metadata_enabled=self.context_metadata_enabled,
            output_summary_enabled=self.output_summary_enabled
        )

    def _load_context_metadata_config(self) -> bool:
        """
        system_config.jsonì—ì„œ context_metadata.enabled ì„¤ì • ë¡œë“œ

        Returns:
            True: context metadata í™œì„±í™”
            False: ë¹„í™œì„±í™” (ê¸°ë³¸ê°’)
        """
        try:
            from ..config import load_system_config
            config = load_system_config()
            enabled = config.get("context_metadata", {}).get("enabled", False)
            logger.debug(
                "Context metadata config loaded",
                enabled=enabled
            )
            return enabled
        except Exception as e:
            logger.warning(
                "Failed to load context_metadata config",
                error=str(e),
                default_value=False
            )
            return False

    async def execute(self, context: WorkerExecutionContext) -> Dict[str, Any]:
        """
        Workerë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤

        Args:
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ì‹¤í–‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
                - content: [{"type": "text", "text": "ì‹¤í–‰ ê²°ê³¼"}]
                - (ì—ëŸ¬ ì‹œ) status: "error", error: "ì—ëŸ¬ ë©”ì‹œì§€"

        Raises:
            ValueError: Worker Agentê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°

        Example:
            >>> context = WorkerExecutionContext(
            ...     worker_name="reviewer",
            ...     task_description="Review module X",
            ...     worker_agent=reviewer_agent
            ... )
            >>> result = await executor.execute(context)
        """
        if not context.worker_agent:
            error_msg = f"âŒ {context.worker_name.capitalize()} Agentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            logger.error("Worker agent not found", worker_name=context.worker_name)
            return {
                "content": [{"type": "text", "text": error_msg}]
            }

        worker_logger = get_logger(
            __name__,
            worker_name=context.worker_name,
            component="WorkerExecution"
        )
        worker_logger.debug(
            "Task execution started",
            task_description=context.task_description[:100]
        )

        # 1. Pre-execution hooks (ë³µì¡ë„: 1)
        pre_exec_result = await self._pre_execute(context)
        if pre_exec_result is not None:
            # Pre-execution ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ë°˜í™˜
            return pre_exec_result

        # 2. Execute worker (ë³µì¡ë„: 1)
        start_time = datetime.now()
        success = False
        error_message = None

        try:
            result = await self._execute_worker_with_timeout(context)
            success = True

        except Exception as e:
            error_message = str(e)
            result = self._handle_error(context, e, worker_logger)

        # 3. Post-execution hooks (ë³µì¡ë„: 1)
        await self._post_execute(context, result, start_time, success, error_message)

        return result

    async def _pre_execute(self, context: WorkerExecutionContext) -> Optional[Dict[str, Any]]:
        """
        ì‹¤í–‰ ì „ ê²€ì¦ ë° ì¤€ë¹„

        Args:
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            None: ê²€ì¦ í†µê³¼
            Dict[str, Any]: ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
        """
        # 1. Review cycle ê´€ë¦¬ (ë³µì¡ë„: 1)
        review_error = self._handle_review_cycle(context)
        if review_error:
            return review_error

        # 2. Commit safety ì²´í¬ (ë³µì¡ë„: 1)
        if context.worker_name == "committer":
            commit_error = await self._validate_commit_safety(context)
            if commit_error:
                return commit_error

        # 3. Workflow callback íŠ¸ë¦¬ê±° (ë³µì¡ë„: 1)
        self.callback_handler.trigger_worker_event(
            worker_name=context.worker_name,
            status="running",
            metadata=context.metadata
        )

        return None

    def _handle_review_cycle(self, context: WorkerExecutionContext) -> Optional[Dict[str, Any]]:
        """
        Review cycle ê´€ë¦¬ (ì´ˆê¸°í™” ë° ì²´í¬)

        Args:
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            None: ê²€ì¦ í†µê³¼
            Dict[str, Any]: Review cycle ìµœëŒ€ì¹˜ ì´ˆê³¼ ì‹œ ì—ëŸ¬ ì‘ë‹µ
        """
        # PlannerëŠ” í•­ìƒ ìƒˆ ì‘ì—…ì˜ ì‹œì‘ì´ë¯€ë¡œ Review cycle ì´ˆê¸°í™”
        if context.worker_name == "planner":
            self.review_manager.reset()
            return None

        # Coder í˜¸ì¶œ ì‹œ
        if context.worker_name == "coder":
            # Reviewer í›„ê°€ ì•„ë‹ˆë©´ ìƒˆ ì‘ì—… ì‹œì‘ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì´ˆê¸°í™”
            if not self.review_manager.coder_called_after_reviewer:
                self.review_manager.reset()
            # Reviewer í›„ Coder í˜¸ì¶œ í‘œì‹œ
            self.review_manager.mark_coder_called()
            return None

        # Reviewer í˜¸ì¶œ ì‹œ cycle count ì²´í¬
        if context.worker_name == "reviewer":
            self.review_manager.mark_reviewer_called()
            should_continue, error_msg = self.review_manager.should_continue_review()

            if not should_continue:
                logger.error(error_msg)
                self.review_manager.reset()
                return {
                    "content": [{"type": "text", "text": error_msg}]
                }

        return None

    async def _validate_commit_safety(self, context: WorkerExecutionContext) -> Optional[Dict[str, Any]]:
        """
        Commit ì•ˆì „ì„± ê²€ì¦

        Args:
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            None: ê²€ì¦ í†µê³¼
            Dict[str, Any]: ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì‘ë‹µ
        """
        validation_result = await self.commit_validator.validate_all()

        if not validation_result.is_safe:
            error_msg = f"âŒ ì»¤ë°‹ ê±°ë¶€ (ë³´ì•ˆ ê²€ì¦ ì‹¤íŒ¨):\n\n{validation_result.error_message}"
            logger.warning(
                f"[{context.worker_name.capitalize()} Tool] ì»¤ë°‹ ê±°ë¶€ (ë¯¼ê° ì •ë³´ ê°ì§€): "
                f"{validation_result.error_message}"
            )
            return {
                "content": [{"type": "text", "text": error_msg}]
            }

        logger.info(
            f"[{context.worker_name.capitalize()} Tool] ë³´ì•ˆ ê²€ì¦ í†µê³¼ - "
            f"{context.worker_name.capitalize()} Agent ì‹¤í–‰"
        )

        return None

    async def _execute_worker_with_timeout(
        self,
        context: WorkerExecutionContext
    ) -> Dict[str, Any]:
        """
        ì‹¤ì œ Worker ì‹¤í–‰ ë¡œì§ (íƒ€ì„ì•„ì›ƒ ì ìš© + ë©”íƒ€ë°ì´í„° ì¶”ê°€)

        Args:
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            Worker ì‹¤í–‰ ê²°ê³¼ (ë©”íƒ€ë°ì´í„° í¬í•¨, tokens_used í¬í•¨)

        Raises:
            asyncio.TimeoutError: íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ
            Exception: Worker ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        """
        # ì—ëŸ¬ í†µê³„: ì‹œë„ ê¸°ë¡
        self.error_manager.record_attempt(context.worker_name)

        # í† í° ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘ (usage_callback)
        tokens_used = {
            'input_tokens': 0,
            'output_tokens': 0,
            'cache_read_tokens': 0,
            'cache_creation_tokens': 0
        }

        def usage_callback(usage_dict: Dict[str, int]):
            """í† í° ì‚¬ìš©ëŸ‰ ì½œë°±"""
            tokens_used['input_tokens'] += usage_dict.get('input_tokens', 0)
            tokens_used['output_tokens'] += usage_dict.get('output_tokens', 0)
            tokens_used['cache_read_tokens'] += usage_dict.get('cache_read_tokens', 0)
            tokens_used['cache_creation_tokens'] += usage_dict.get('cache_creation_tokens', 0)

        async def execute():
            result = ""
            async for chunk in context.worker_agent.execute_task(
                context.task_description,
                usage_callback=usage_callback
            ):
                result += chunk
                # Worker ì¶œë ¥ ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í˜¸ì¶œ (TUIìš©, raw ì¶œë ¥)
                if context.worker_output_callback:
                    try:
                        context.worker_output_callback(context.worker_name, chunk)
                    except Exception as e:
                        logger.warning(f"Worker ì¶œë ¥ ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨: {e}")

            # ì›ë³¸ ì¶œë ¥ ë³´ê´€
            raw_output = result

            # 1. Worker ì¶œë ¥ ìš”ì•½ (í™œì„±í™”ëœ ê²½ìš°)
            if self.output_summary_enabled:
                result = self._summarize_worker_output(result, context)

            # 2. Context metadata ì¶”ê°€ (í™œì„±í™”ëœ ê²½ìš°)
            if self.context_metadata_enabled:
                result = self._add_context_metadata(result, context)

            # Worker ì¶œë ¥ ë°˜í™˜ (ìš”ì•½ëœ ë²„ì „ + raw_output + tokens_used ë³´ê´€)
            return {
                "content": [{"type": "text", "text": result}],
                "raw_output": raw_output,
                "tokens_used": tokens_used
            }

        # ì¬ì‹œë„ ë¡œì§ ë˜ëŠ” ì¼ë°˜ ì‹¤í–‰ (ë³µì¡ë„: 1)
        if context.use_retry:
            from src.infrastructure.mcp.worker_tools import retry_with_backoff
            result = await asyncio.wait_for(
                retry_with_backoff(execute, context.worker_name),
                timeout=context.timeout
            )
        else:
            result = await asyncio.wait_for(execute(), timeout=context.timeout)

        return result

    def _add_context_metadata(
        self,
        worker_output: str,
        context: WorkerExecutionContext
    ) -> str:
        """
        Worker ì¶œë ¥ì— ì»¨í…ìŠ¤íŠ¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€

        Args:
            worker_output: Workerì˜ raw ì¶œë ¥
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ë©”íƒ€ë°ì´í„°ê°€ ì¶”ê°€ëœ ì¶œë ¥
        """
        try:
            # Artifact ê²½ë¡œ ìƒì„± (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
            artifact_path = None
            if context.session_id:
                from ..storage.artifact_storage import get_artifact_storage
                storage = get_artifact_storage()
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                artifact_id = f"{context.worker_name}_{timestamp}"
                artifact_path = str(storage.get_artifact_path(
                    artifact_id,
                    session_id=context.session_id
                ))

            # Dependencies ì¶”ì¶œ (metadataì—ì„œ)
            dependencies = context.metadata.get("dependencies", [])

            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            enhanced_output = self.metadata_formatter.format_worker_output(
                worker_name=context.worker_name,
                output=worker_output,
                artifact_path=artifact_path,
                dependencies=dependencies
            )

            logger.debug(
                "Context metadata added to worker output",
                worker_name=context.worker_name,
                has_artifact=artifact_path is not None,
                dependencies_count=len(dependencies)
            )

            return enhanced_output

        except Exception as e:
            logger.warning(
                "Failed to add context metadata",
                worker_name=context.worker_name,
                error=str(e)
            )
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¶œë ¥ ë°˜í™˜
            return worker_output

    def _summarize_worker_output(
        self,
        worker_output: str,
        context: WorkerExecutionContext
    ) -> str:
        """
        Worker ì¶œë ¥ì„ ìë™ ìš”ì•½

        Args:
            worker_output: Workerì˜ raw ì¶œë ¥
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸

        Returns:
            ìš”ì•½ëœ ì¶œë ¥ (artifact ê²½ë¡œ í¬í•¨)
        """
        try:
            # Artifact ì €ì¥ (ì „ì²´ ë¡œê·¸)
            if context.session_id:
                from ..storage.artifact_storage import get_artifact_storage
                storage = get_artifact_storage()
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                artifact_id = f"{context.worker_name}_{timestamp}"

                # ì „ì²´ ë¡œê·¸ë¥¼ artifact íŒŒì¼ë¡œ ì €ì¥
                artifact_path = storage.save_artifact(
                    artifact_id=artifact_id,
                    content=worker_output,
                    session_id=context.session_id
                )

                # 3ë‹¨ê³„ ìš”ì•½ ìƒì„±
                summary = self.output_summarizer.summarize(
                    worker_name=context.worker_name,
                    full_output=worker_output,
                    artifact_path=str(artifact_path)
                )

                # ìš”ì•½ í¬ë§·íŒ…
                summarized = self.output_summarizer.format_summary_output(
                    worker_name=context.worker_name,
                    summary=summary
                )

                logger.info(
                    "Worker output summarized",
                    worker_name=context.worker_name,
                    original_length=len(worker_output),
                    summary_length=len(summarized),
                    reduction_ratio=f"{(1 - len(summarized)/len(worker_output))*100:.1f}%",
                    artifact_path=str(artifact_path)
                )

                return summarized
            else:
                # ì„¸ì…˜ IDê°€ ì—†ìœ¼ë©´ ìš”ì•½ ì—†ì´ ì›ë³¸ ë°˜í™˜
                logger.debug(
                    "Session ID not found, skipping summarization",
                    worker_name=context.worker_name
                )
                return worker_output

        except Exception as e:
            logger.warning(
                "Failed to summarize worker output",
                worker_name=context.worker_name,
                error=str(e)
            )
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì¶œë ¥ ë°˜í™˜
            return worker_output

    async def _post_execute(
        self,
        context: WorkerExecutionContext,
        result: Dict[str, Any],
        start_time: datetime,
        success: bool,
        error_message: Optional[str]
    ) -> None:
        """
        ì‹¤í–‰ í›„ ì²˜ë¦¬

        Args:
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
            result: ì‹¤í–‰ ê²°ê³¼
            start_time: ì‹¤í–‰ ì‹œì‘ ì‹œê°
            success: ì„±ê³µ ì—¬ë¶€
            error_message: ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        """
        # Review cycle ì™„ë£Œ ê¸°ë¡ (ë³µì¡ë„: 1)
        if context.worker_name == "reviewer" and success:
            # Review ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì—¬ critical issues ì¶”ì¶œ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            reviewer_output = result.get("content", [{}])[0].get("text", "")
            critical_issues = self._extract_critical_issues(reviewer_output)

            self.review_manager.record_review_result(
                critical_issues=critical_issues,
                reviewer_output=reviewer_output[:500]  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„
            )

        # ì›Œí¬í”Œë¡œìš° ì½œë°± (ë³µì¡ë„: 1)
        if success:
            self.callback_handler.trigger_worker_event(
                worker_name=context.worker_name,
                status="completed",
                metadata=context.metadata
            )
        else:
            self.callback_handler.trigger_worker_event(
                worker_name=context.worker_name,
                status="failed",
                error=error_message,
                metadata=context.metadata
            )

        # ë©”íŠ¸ë¦­ ê¸°ë¡ (ë³µì¡ë„: 1)
        if context.metrics_collector and context.session_id:
            end_time = datetime.now()
            try:
                # tokens_used ì¶”ì¶œ (resultì—ì„œ)
                tokens_used_dict = result.get("tokens_used", None)
                total_tokens = None
                input_tokens = None
                output_tokens = None
                cache_read_tokens = None
                cache_creation_tokens = None

                if tokens_used_dict:
                    input_tokens = tokens_used_dict.get('input_tokens', 0)
                    output_tokens = tokens_used_dict.get('output_tokens', 0)
                    cache_read_tokens = tokens_used_dict.get('cache_read_tokens', 0)
                    cache_creation_tokens = tokens_used_dict.get('cache_creation_tokens', 0)
                    total_tokens = input_tokens + output_tokens

                    logger.debug(
                        "Token usage recorded",
                        worker_name=context.worker_name,
                        input_tokens=input_tokens,
                        output_tokens=output_tokens,
                        cache_read_tokens=cache_read_tokens,
                        cache_creation_tokens=cache_creation_tokens,
                        total_tokens=total_tokens
                    )

                context.metrics_collector.record_worker_execution(
                    session_id=context.session_id,
                    worker_name=context.worker_name,
                    task_description=context.task_description[:100],
                    start_time=start_time,
                    end_time=end_time,
                    success=success,
                    tokens_used=total_tokens,
                    input_tokens=input_tokens,
                    output_tokens=output_tokens,
                    cache_read_tokens=cache_read_tokens,
                    cache_creation_tokens=cache_creation_tokens,
                    error_message=error_message,
                )
            except Exception as metrics_error:
                logger.warning(f"ë©”íŠ¸ë¦­ ê¸°ë¡ ì‹¤íŒ¨: {metrics_error}")

    def _handle_error(
        self,
        context: WorkerExecutionContext,
        error: Exception,
        worker_logger: logging.Logger
    ) -> Dict[str, Any]:
        """
        ì—ëŸ¬ ì²˜ë¦¬

        Args:
            context: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
            error: ë°œìƒí•œ ì˜ˆì™¸
            worker_logger: Worker ì „ìš© ë¡œê±°

        Returns:
            ì—ëŸ¬ ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
        """
        # ì—ëŸ¬ í†µê³„ ê¸°ë¡
        self.error_manager.record_error(
            worker_name=context.worker_name,
            error=error,
            context=context.to_dict()
        )

        # íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ ì²˜ë¦¬ (ë³µì¡ë„: 1)
        if isinstance(error, asyncio.TimeoutError):
            worker_logger.error(
                "Task execution timeout",
                timeout_seconds=context.timeout,
                exc_info=True
            )

            return {
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"âŒ {context.worker_name.capitalize()} ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ\n\n"
                            f"ì‘ì—…ì´ {context.timeout}ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                            f"í™˜ê²½ë³€ìˆ˜ WORKER_TIMEOUT_{context.worker_name.upper()}ë¥¼ "
                            f"ì¡°ì •í•˜ì—¬ íƒ€ì„ì•„ì›ƒì„ ëŠ˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                        )
                    }
                ]
            }

        # ì¼ë°˜ ì—ëŸ¬ ì²˜ë¦¬ (ë³µì¡ë„: 1)
        log_exception_silently(
            worker_logger,
            error,
            f"Worker Tool ({context.worker_name}) execution failed",
            worker_name=context.worker_name,
            task_description=context.task_description[:100]
        )

        return {
            "content": [
                {
                    "type": "text",
                    "text": (
                        f"âŒ {context.worker_name.capitalize()} ì‹¤í–‰ ì‹¤íŒ¨\n\n"
                        f"ì—ëŸ¬: {error}\n\n"
                        f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ëŠ” ì—ëŸ¬ ë¡œê·¸ "
                        f"(~/.better-llm/{{project}}/logs/better-llm-error.log)ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    )
                }
            ]
        }

    def _extract_critical_issues(self, reviewer_output: str) -> list[str]:
        """
        Reviewer ì¶œë ¥ì—ì„œ ì¤‘ìš” ì´ìŠˆ ì¶”ì¶œ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)

        Args:
            reviewer_output: Reviewer ì¶œë ¥ í…ìŠ¤íŠ¸

        Returns:
            ì¤‘ìš” ì´ìŠˆ ëª©ë¡
        """
        critical_keywords = ["critical", "error", "bug", "security", "vulnerability"]
        issues = []

        for line in reviewer_output.split("\n"):
            line_lower = line.lower()
            if any(keyword in line_lower for keyword in critical_keywords):
                issues.append(line.strip()[:100])  # ìµœëŒ€ 100ì

        return issues[:10]  # ìµœëŒ€ 10ê°œ

    def _summarize_worker_output(self, worker_name: str, output: str) -> str:
        """
        Worker ì¶œë ¥ì„ ìš”ì•½í•˜ì—¬ Managerì—ê²Œ ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì ˆì•½í•©ë‹ˆë‹¤.

        ì œê±° ëŒ€ìƒ:
        - íŒŒì¼ ì½ê¸° ê²°ê³¼ (Read, cat ë“±ì˜ ê¸´ ì¶œë ¥)
        - íŒŒì¼ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ (Grep, Globì˜ ê¸´ ë¦¬ìŠ¤íŠ¸)
        - ê¸´ ì½”ë“œ ë¸”ë¡ (500ì ì´ìƒ)
        - ë””ë²„ê·¸ ë¡œê·¸

        ìœ ì§€ ëŒ€ìƒ:
        - ì—ëŸ¬ ë©”ì‹œì§€
        - ìµœì¢… ê²°ë¡ /ì™„ë£Œ ë©”ì‹œì§€
        - í•µì‹¬ ê²°ì • ì‚¬í•­
        - ìš”ì•½ ì„¹ì…˜
        - í†µê³„ ì •ë³´

        Args:
            worker_name: Worker ì´ë¦„
            output: Workerì˜ raw ì¶œë ¥

        Returns:
            ìš”ì•½ëœ ì¶œë ¥
        """
        lines = output.split("\n")
        summarized_lines = []
        in_code_block = False
        code_block_lines = []
        skip_file_content = False
        file_read_count = 0

        for i, line in enumerate(lines):
            # ì½”ë“œ ë¸”ë¡ ì‹œì‘/ì¢…ë£Œ ê°ì§€
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                if not in_code_block and code_block_lines:
                    # ì½”ë“œ ë¸”ë¡ ì¢…ë£Œ - ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
                    if len(code_block_lines) > 20:
                        summarized_lines.append("```")
                        summarized_lines.append(f"... ({len(code_block_lines)} lines of code omitted)")
                        summarized_lines.append("```")
                    else:
                        summarized_lines.extend(code_block_lines)
                        summarized_lines.append(line)
                    code_block_lines = []
                else:
                    code_block_lines.append(line)
                continue

            if in_code_block:
                code_block_lines.append(line)
                continue

            # íŒŒì¼ ì½ê¸° ê²°ê³¼ ê°ì§€ ë° ìš”ì•½
            if re.search(r"Reading|read file|íŒŒì¼ ì½ê¸°", line, re.IGNORECASE):
                file_read_count += 1
                summarized_lines.append(f"ğŸ“„ íŒŒì¼ ì½ê¸° #{file_read_count}: {line.strip()[:80]}")
                skip_file_content = True
                continue

            if skip_file_content:
                # íŒŒì¼ ë‚´ìš©ì€ ê±´ë„ˆë›°ê³  ë‹¤ìŒ ì•¡ì…˜ê¹Œì§€ë§Œ ìŠ¤í‚µ
                if re.search(r"^(Writing|Editing|Running|Searching|Complete|ì™„ë£Œ|ì—ëŸ¬|Error)", line, re.IGNORECASE):
                    skip_file_content = False
                else:
                    continue

            # íŒŒì¼ ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ (Grep, Glob)
            if re.search(r"(Found|ê²€ìƒ‰|Searching|Grepping)", line, re.IGNORECASE):
                summarized_lines.append(f"ğŸ” {line.strip()[:100]}")
                # ë‹¤ìŒ 10ì¤„ ì •ë„ëŠ” ìƒì„¸ ê²°ê³¼ì´ë¯€ë¡œ ìŠ¤í‚µ
                next_lines = lines[i+1:i+10]
                match_count = sum(1 for l in next_lines if l.strip() and not l.startswith("#"))
                if match_count > 5:
                    summarized_lines.append(f"   ... ({match_count}ê°œ ê²°ê³¼ ìƒëµ)")
                continue

            # ì¤‘ìš” ì„¹ì…˜ ìœ ì§€ (ì—ëŸ¬, ì™„ë£Œ, ê²°ì •, ìš”ì•½)
            if re.search(r"(Error|ì—ëŸ¬|Failed|ì‹¤íŒ¨|Warning|ê²½ê³ |Critical|ì¤‘ìš”)", line, re.IGNORECASE):
                summarized_lines.append(f"âš ï¸  {line.strip()}")
                continue

            if re.search(r"(Complete|ì™„ë£Œ|Success|ì„±ê³µ|Done|Finished)", line, re.IGNORECASE):
                summarized_lines.append(f"âœ… {line.strip()}")
                continue

            if re.search(r"(Summary|ìš”ì•½|Conclusion|ê²°ë¡ |Decision|ê²°ì •)", line, re.IGNORECASE):
                summarized_lines.append(f"ğŸ“‹ {line.strip()}")
                continue

            # í†µê³„ ì •ë³´ ìœ ì§€
            if re.search(r"\d+\s*(files?|ê°œ|ê±´|ì¤„|lines?)", line, re.IGNORECASE):
                summarized_lines.append(line.strip())
                continue

            # ë¹ˆ ì¤„ì´ ì•„ë‹ˆê³  ë„ˆë¬´ ê¸¸ì§€ ì•Šìœ¼ë©´ ìœ ì§€
            if line.strip() and len(line) < 200:
                # ë””ë²„ê·¸ ë¡œê·¸ë‚˜ ë°˜ë³µì ì¸ ë‚´ìš©ì€ ì œì™¸
                if not re.search(r"(DEBUG|TRACE|Received chunk|ì²­í¬|ìŠ¤íŠ¸ë¦¬ë°)", line, re.IGNORECASE):
                    summarized_lines.append(line.strip())

        # ìµœì¢… ìš”ì•½
        summarized = "\n".join(summarized_lines)

        # ìš”ì•½ í†µê³„
        original_length = len(output)
        summarized_length = len(summarized)
        reduction_ratio = (1 - summarized_length / original_length) * 100 if original_length > 0 else 0

        # ìš”ì•½ì´ ì˜ë¯¸ ìˆëŠ” ê²½ìš° (30% ì´ìƒ ê°ì†Œ)ì—ë§Œ ì ìš©
        if reduction_ratio >= 30:
            logger.info(
                f"[{worker_name}] ì¶œë ¥ ìš”ì•½ ì™„ë£Œ: {original_length} â†’ {summarized_length} chars "
                f"({reduction_ratio:.1f}% ê°ì†Œ)"
            )
            return summarized
        else:
            # ìš”ì•½ íš¨ê³¼ê°€ ì ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
            logger.debug(f"[{worker_name}] ìš”ì•½ íš¨ê³¼ ë¯¸ë¯¸ ({reduction_ratio:.1f}%), ì›ë³¸ ìœ ì§€")
            return output

    def set_review_max_cycles(self, max_cycles: int) -> None:
        """
        Review cycle ìµœëŒ€ íšŸìˆ˜ ì„¤ì •

        Args:
            max_cycles: ìµœëŒ€ Review cycle íšŸìˆ˜
        """
        self.review_manager.max_cycles = max_cycles
        logger.info(f"Review cycle max_cycles updated: {max_cycles}")

    def get_error_summary(self) -> Dict[str, Any]:
        """
        ì—ëŸ¬ í†µê³„ ìš”ì•½ ì¡°íšŒ

        Returns:
            ì—ëŸ¬ í†µê³„ ìš”ì•½ ë”•ì…”ë„ˆë¦¬
        """
        return self.error_manager.export_to_dict()

    def reset_review_cycle(self) -> None:
        """Review cycle ì´ˆê¸°í™”"""
        self.review_manager.reset()

    def reset_error_statistics(self) -> None:
        """ì—ëŸ¬ í†µê³„ ì´ˆê¸°í™”"""
        self.error_manager.reset_statistics()

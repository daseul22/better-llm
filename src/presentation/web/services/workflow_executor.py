"""
ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„

ì›Œí¬í”Œë¡œìš°ì˜ ë…¸ë“œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³ , ë…¸ë“œ ê°„ ë°ì´í„° ì „ë‹¬ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import asyncio
import time
from datetime import datetime
from typing import Dict, Any, AsyncIterator, Set, List, Optional
from collections import deque
from dataclasses import replace

from src.domain.models import AgentConfig, Message
from src.infrastructure.config import JsonConfigLoader, get_project_root
from src.infrastructure.claude.worker_client import WorkerAgent
from src.infrastructure.claude.manager_client import ManagerAgent
from src.infrastructure.logging import get_logger, add_session_file_handlers, remove_session_file_handlers
from src.presentation.web.schemas.workflow import (
    Workflow,
    WorkflowNode,
    WorkflowEdge,
    WorkflowNodeExecutionEvent,
    WorkerNodeData,
    ManagerNodeData,
    InputNodeData,
    ConditionNodeData,
    LoopNodeData,
    MergeNodeData,
    TokenUsage,
)

logger = get_logger(__name__)


class WorkflowExecutor:
    """
    ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„

    ì›Œí¬í”Œë¡œìš°ì˜ ë…¸ë“œë¥¼ ìœ„ìƒ ì •ë ¬í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³ ,
    ê° ë…¸ë“œì˜ ì¶œë ¥ì„ ë‹¤ìŒ ë…¸ë“œì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.

    Attributes:
        config_loader: Agent ì„¤ì • ë¡œë”
        agent_configs: Agent ì„¤ì • ëª©ë¡ (ìºì‹œ)
    """

    def __init__(self, config_loader: JsonConfigLoader):
        """
        WorkflowExecutor ì´ˆê¸°í™”

        Args:
            config_loader: Agent ì„¤ì • ë¡œë”
        """
        self.config_loader = config_loader
        self.agent_configs = config_loader.load_agent_configs()
        self.agent_config_map = {
            config.name: config for config in self.agent_configs
        }

    def _get_agent_config(self, agent_name: str) -> AgentConfig:
        """
        Agent ì„¤ì • ì¡°íšŒ

        Args:
            agent_name: Agent ì´ë¦„

        Returns:
            AgentConfig: Agent ì„¤ì •

        Raises:
            ValueError: Agentë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        """
        config = self.agent_config_map.get(agent_name)
        if not config:
            raise ValueError(f"Agent '{agent_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return config

    def _topological_sort(
        self, nodes: List[WorkflowNode], edges: List[WorkflowEdge]
    ) -> List[WorkflowNode]:
        """
        ì›Œí¬í”Œë¡œìš° ë…¸ë“œ ìœ„ìƒ ì •ë ¬ (Topological Sort)

        Args:
            nodes: ë…¸ë“œ ëª©ë¡
            edges: ì—£ì§€ ëª©ë¡

        Returns:
            List[WorkflowNode]: ì‹¤í–‰ ìˆœì„œëŒ€ë¡œ ì •ë ¬ëœ ë…¸ë“œ ëª©ë¡

        Raises:
            ValueError: ìˆœí™˜ ì°¸ì¡°ê°€ ìˆëŠ” ê²½ìš°
        """
        # ë…¸ë“œ ID â†’ ë…¸ë“œ ë§¤í•‘
        node_map = {node.id: node for node in nodes}

        # ìœ íš¨í•˜ì§€ ì•Šì€ ì—£ì§€ í•„í„°ë§ (ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œë¥¼ ì°¸ì¡°í•˜ëŠ” ì—£ì§€ ì œê±°)
        valid_edges = []
        for edge in edges:
            if edge.source not in node_map:
                logger.warning(
                    f"ì—£ì§€ {edge.id}: source ë…¸ë“œ '{edge.source}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì—£ì§€ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤."
                )
                continue
            if edge.target not in node_map:
                logger.warning(
                    f"ì—£ì§€ {edge.id}: target ë…¸ë“œ '{edge.target}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì—£ì§€ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤."
                )
                continue
            valid_edges.append(edge)

        # Input ë…¸ë“œ ì°¾ê¸° (ì‹œì‘ì )
        input_nodes = [node for node in nodes if node.type == "input"]
        if not input_nodes:
            raise ValueError("ì›Œí¬í”Œë¡œìš°ì— Input ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤. Input ë…¸ë“œì—ì„œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")

        # ì—¬ëŸ¬ Input ë…¸ë“œê°€ ìˆëŠ” ê²½ìš° ëª¨ë‘ ì‹œì‘ì ìœ¼ë¡œ ì‚¬ìš©
        input_node_ids = [node.id for node in input_nodes]

        # ì¸ì ‘ ë¦¬ìŠ¤íŠ¸ (ë…¸ë“œ ID â†’ ìì‹ ë…¸ë“œ ID ëª©ë¡)
        adjacency: Dict[str, List[str]] = {node.id: [] for node in nodes}
        in_degree: Dict[str, int] = {node.id: 0 for node in nodes}

        for edge in valid_edges:
            adjacency[edge.source].append(edge.target)
            in_degree[edge.target] += 1

        # Input ë…¸ë“œì—ì„œ ë„ë‹¬ ê°€ëŠ¥í•œ ë…¸ë“œë§Œ í•„í„°ë§ (BFS)
        reachable_nodes = set(input_node_ids)
        bfs_queue = deque(input_node_ids)

        while bfs_queue:
            current_id = bfs_queue.popleft()
            for child_id in adjacency[current_id]:
                if child_id not in reachable_nodes:
                    reachable_nodes.add(child_id)
                    bfs_queue.append(child_id)

        # ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ ë…¸ë“œ ê²½ê³ 
        unreachable_nodes = [node.id for node in nodes if node.id not in reachable_nodes]
        if unreachable_nodes:
            logger.warning(
                f"Input ë…¸ë“œì—ì„œ ë„ë‹¬í•  ìˆ˜ ì—†ëŠ” ë…¸ë“œê°€ ìˆìŠµë‹ˆë‹¤: {unreachable_nodes}. "
                "ì´ ë…¸ë“œë“¤ì€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )

        # ë„ë‹¬ ê°€ëŠ¥í•œ ë…¸ë“œë§Œìœ¼ë¡œ ìœ„ìƒ ì •ë ¬ ìˆ˜í–‰
        # Input ë…¸ë“œë§Œ ì‹œì‘ì ìœ¼ë¡œ ì„¤ì •
        queue = deque(input_node_ids)
        sorted_nodes = []
        visited = set()

        while queue:
            node_id = queue.popleft()

            if node_id in visited:
                continue

            # ë„ë‹¬ ë¶ˆê°€ëŠ¥í•œ ë…¸ë“œëŠ” ê±´ë„ˆëœ€
            if node_id not in reachable_nodes:
                continue

            # ëª¨ë“  ë¶€ëª¨ ë…¸ë“œê°€ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
            parents_ready = True
            for edge in valid_edges:
                if edge.target == node_id and edge.source in reachable_nodes:
                    if edge.source not in visited:
                        parents_ready = False
                        break

            if not parents_ready:
                # ë¶€ëª¨ ë…¸ë“œê°€ ì•„ì§ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í ë’¤ë¡œ
                queue.append(node_id)
                continue

            visited.add(node_id)
            sorted_nodes.append(node_map[node_id])

            # ìì‹ ë…¸ë“œë¥¼ íì— ì¶”ê°€
            for child_id in adjacency[node_id]:
                if child_id not in visited and child_id in reachable_nodes:
                    queue.append(child_id)

        # ìˆœí™˜ ì°¸ì¡° ê²€ì‚¬ (ë„ë‹¬ ê°€ëŠ¥í•œ ë…¸ë“œ ê¸°ì¤€)
        if len(sorted_nodes) != len(reachable_nodes):
            raise ValueError("ì›Œí¬í”Œë¡œìš°ì— ìˆœí™˜ ì°¸ì¡°ê°€ ìˆìŠµë‹ˆë‹¤")

        return sorted_nodes

    def _get_parent_nodes(
        self, node_id: str, edges: List[WorkflowEdge]
    ) -> List[str]:
        """
        ë…¸ë“œì˜ ë¶€ëª¨ ë…¸ë“œ ID ëª©ë¡ ì¡°íšŒ

        Args:
            node_id: ë…¸ë“œ ID
            edges: ì—£ì§€ ëª©ë¡

        Returns:
            List[str]: ë¶€ëª¨ ë…¸ë“œ ID ëª©ë¡
        """
        return [edge.source for edge in edges if edge.target == node_id]

    def _render_task_template(
        self,
        template: str,
        node_id: str,
        node_outputs: Dict[str, str],
        initial_input: str,
    ) -> str:
        """
        ì‘ì—… ì„¤ëª… í…œí”Œë¦¿ ë Œë”ë§

        ë³€ìˆ˜:
        - {{input}}: ì´ˆê¸° ì…ë ¥ (ì²« ë²ˆì§¸ ë…¸ë“œ)
        - {{node_<id>}}: íŠ¹ì • ë…¸ë“œì˜ ì¶œë ¥
        - {{parent}}: ë¶€ëª¨ ë…¸ë“œì˜ ì¶œë ¥ (ë¶€ëª¨ê°€ 1ê°œì¸ ê²½ìš°)

        Args:
            template: í…œí”Œë¦¿ ë¬¸ìì—´
            node_id: í˜„ì¬ ë…¸ë“œ ID
            node_outputs: ë…¸ë“œ ID â†’ ì¶œë ¥ ë§¤í•‘
            initial_input: ì´ˆê¸° ì…ë ¥

        Returns:
            str: ë Œë”ë§ëœ ì‘ì—… ì„¤ëª…
        """
        result = template

        # {{input}} ì¹˜í™˜
        result = result.replace("{{input}}", initial_input)

        # {{node_<id>}} ì¹˜í™˜
        for nid, output in node_outputs.items():
            result = result.replace(f"{{{{node_{nid}}}}}", output)

        # {{parent}} ì¹˜í™˜ (ë¶€ëª¨ê°€ 1ê°œì¸ ê²½ìš°ë§Œ ì§€ì›)
        if "{{parent}}" in result:
            parent_nodes = [
                nid for nid in node_outputs.keys()
                if nid in result  # ì„ì‹œ: ë” ì •êµí•œ ë¡œì§ í•„ìš”
            ]
            if len(parent_nodes) == 1:
                result = result.replace("{{parent}}", node_outputs[parent_nodes[0]])

        return result

    def _evaluate_condition(
        self,
        condition_type: str,
        condition_value: str,
        input_text: str
    ) -> bool:
        """
        ì¡°ê±´ í‰ê°€

        Args:
            condition_type: ì¡°ê±´ íƒ€ì… ('contains', 'regex', 'length', 'custom')
            condition_value: ì¡°ê±´ ê°’
            input_text: í‰ê°€í•  í…ìŠ¤íŠ¸

        Returns:
            bool: ì¡°ê±´ì´ Trueì¸ì§€ ì—¬ë¶€
        """
        import re

        if condition_type == "contains":
            # í…ìŠ¤íŠ¸ í¬í•¨ ê²€ì‚¬
            return condition_value in input_text

        elif condition_type == "regex":
            # ì •ê·œí‘œí˜„ì‹ ë§¤ì¹­
            try:
                pattern = re.compile(condition_value)
                return bool(pattern.search(input_text))
            except re.error as e:
                logger.error(f"ì •ê·œí‘œí˜„ì‹ ì˜¤ë¥˜: {e}")
                return False

        elif condition_type == "length":
            # ê¸¸ì´ ë¹„êµ (ì˜ˆ: ">100", "<=500", "==0")
            try:
                text_length = len(input_text)
                # condition_valueë¥¼ íŒŒì‹±í•˜ì—¬ ë¹„êµ
                if condition_value.startswith(">="):
                    threshold = int(condition_value[2:].strip())
                    return text_length >= threshold
                elif condition_value.startswith("<="):
                    threshold = int(condition_value[2:].strip())
                    return text_length <= threshold
                elif condition_value.startswith(">"):
                    threshold = int(condition_value[1:].strip())
                    return text_length > threshold
                elif condition_value.startswith("<"):
                    threshold = int(condition_value[1:].strip())
                    return text_length < threshold
                elif condition_value.startswith("=="):
                    threshold = int(condition_value[2:].strip())
                    return text_length == threshold
                else:
                    # ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° == ë¡œ ê°„ì£¼
                    threshold = int(condition_value.strip())
                    return text_length == threshold
            except (ValueError, IndexError) as e:
                logger.error(f"ê¸¸ì´ ì¡°ê±´ íŒŒì‹± ì˜¤ë¥˜: {e}")
                return False

        elif condition_type == "custom":
            # ì»¤ìŠ¤í…€ Python í‘œí˜„ì‹ í‰ê°€
            try:
                # ì•ˆì „í•œ í‰ê°€ë¥¼ ìœ„í•´ ì œí•œëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì‚¬ìš©
                namespace = {
                    "output": input_text,
                    "len": len,
                    "str": str,
                    "int": int,
                    "float": float,
                }
                result = eval(condition_value, {"__builtins__": {}}, namespace)
                return bool(result)
            except Exception as e:
                logger.error(f"ì»¤ìŠ¤í…€ ì¡°ê±´ í‰ê°€ ì˜¤ë¥˜: {e}")
                return False

        else:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¡°ê±´ íƒ€ì…: {condition_type}")
            return False

    async def _execute_condition_node(
        self,
        node: WorkflowNode,
        node_outputs: Dict[str, str],
        edges: List[WorkflowEdge],
        session_id: str,
    ) -> tuple[str, str]:
        """
        ì¡°ê±´ ë¶„ê¸° ë…¸ë“œ ì‹¤í–‰

        Args:
            node: ì¡°ê±´ ë…¸ë“œ
            node_outputs: ì´ì „ ë…¸ë“œ ì¶œë ¥ë“¤
            edges: ì—£ì§€ ëª©ë¡ (ë¶„ê¸° ê²½ë¡œ í™•ì¸ìš©)
            session_id: ì„¸ì…˜ ID

        Returns:
            tuple[str, str]: (ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œ ID, ì¡°ê±´ í‰ê°€ ê²°ê³¼ í…ìŠ¤íŠ¸)

        Raises:
            ValueError: ë¶€ëª¨ ë…¸ë“œê°€ ì—†ê±°ë‚˜ ë¶„ê¸° ê²½ë¡œê°€ ì—†ëŠ” ê²½ìš°
        """
        node_id = node.id
        node_data: ConditionNodeData = node.data  # type: ignore

        logger.info(
            f"[{session_id}] ì¡°ê±´ ë…¸ë“œ ì‹¤í–‰: {node_id} "
            f"(íƒ€ì…: {node_data.condition_type}, ê°’: {node_data.condition_value})"
        )

        # ë¶€ëª¨ ë…¸ë“œ ì¶œë ¥ ê°€ì ¸ì˜¤ê¸°
        parent_nodes = self._get_parent_nodes(node_id, edges)
        if not parent_nodes:
            raise ValueError(f"ì¡°ê±´ ë…¸ë“œ {node_id}ì— ë¶€ëª¨ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤")

        # ì²« ë²ˆì§¸ ë¶€ëª¨ ë…¸ë“œì˜ ì¶œë ¥ ì‚¬ìš©
        parent_id = parent_nodes[0]
        parent_output = node_outputs.get(parent_id, "")

        # ì¡°ê±´ í‰ê°€
        condition_result = self._evaluate_condition(
            node_data.condition_type,
            node_data.condition_value,
            parent_output
        )

        logger.info(
            f"[{session_id}] ì¡°ê±´ í‰ê°€ ê²°ê³¼: {condition_result} "
            f"(ì…ë ¥ ê¸¸ì´: {len(parent_output)})"
        )

        # ë¶„ê¸° ê²½ë¡œ ê²°ì • (ì—£ì§€ì˜ sourceHandleì„ ì‚¬ìš©)
        # sourceHandleì´ "true"ì¸ ì—£ì§€ â†’ True ê²½ë¡œ
        # sourceHandleì´ "false"ì¸ ì—£ì§€ â†’ False ê²½ë¡œ
        next_node_id = None
        for edge in edges:
            if edge.source == node_id:
                if condition_result and edge.sourceHandle == "true":
                    next_node_id = edge.target
                    break
                elif not condition_result and edge.sourceHandle == "false":
                    next_node_id = edge.target
                    break

        if next_node_id is None:
            branch_type = "true" if condition_result else "false"
            raise ValueError(
                f"ì¡°ê±´ ë…¸ë“œ {node_id}ì˜ {branch_type} ë¶„ê¸° ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤. "
                f"sourceHandleì´ '{branch_type}'ì¸ ì—£ì§€ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
            )

        # ì¡°ê±´ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        result_text = f"ì¡°ê±´ í‰ê°€ ê²°ê³¼: {condition_result}\në¶„ê¸°: {next_node_id}"

        return next_node_id, result_text

    async def _execute_loop_node(
        self,
        node: WorkflowNode,
        node_outputs: Dict[str, str],
        edges: List[WorkflowEdge],
        nodes: List[WorkflowNode],
        initial_input: str,
        session_id: str,
        project_path: Optional[str] = None,
    ) -> AsyncIterator[WorkflowNodeExecutionEvent]:
        """
        ë°˜ë³µ ë…¸ë“œ ì‹¤í–‰

        Args:
            node: ë°˜ë³µ ë…¸ë“œ
            node_outputs: ì´ì „ ë…¸ë“œ ì¶œë ¥ë“¤
            edges: ì—£ì§€ ëª©ë¡
            nodes: ë…¸ë“œ ëª©ë¡
            initial_input: ì´ˆê¸° ì…ë ¥
            session_id: ì„¸ì…˜ ID
            project_path: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (CLAUDE.md ë¡œë“œìš©)

        Yields:
            WorkflowNodeExecutionEvent: ë…¸ë“œ ì‹¤í–‰ ì´ë²¤íŠ¸
        """
        node_id = node.id
        node_data: LoopNodeData = node.data  # type: ignore

        logger.info(
            f"[{session_id}] ë°˜ë³µ ë…¸ë“œ ì‹œì‘: {node_id} "
            f"(ìµœëŒ€ ë°˜ë³µ: {node_data.max_iterations}, ì¡°ê±´: {node_data.loop_condition})"
        )

        # ë…¸ë“œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ë…¸ë“œ ì‹œì‘ ì´ë²¤íŠ¸
        yield WorkflowNodeExecutionEvent(
            event_type="node_start",
            node_id=node_id,
            data={
                "node_type": "loop",
                "max_iterations": node_data.max_iterations,
            },
            timestamp=datetime.now().isoformat(),
        )

        try:
            # ë£¨í”„ ë³¸ë¬¸ ë…¸ë“œ ì°¾ê¸° (loop ë…¸ë“œì˜ ìì‹ ë…¸ë“œë“¤)
            loop_body_node_ids = [
                edge.target for edge in edges if edge.source == node_id
            ]

            if not loop_body_node_ids:
                raise ValueError(f"ë°˜ë³µ ë…¸ë“œ {node_id}ì— ìì‹ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤")

            iteration = 0
            loop_output_history = []

            while iteration < node_data.max_iterations:
                iteration += 1

                yield WorkflowNodeExecutionEvent(
                    event_type="node_output",
                    node_id=node_id,
                    data={"chunk": f"\n\n--- ë°˜ë³µ {iteration}íšŒì°¨ ì‹œì‘ ---\n\n"},
                )

                logger.info(f"[{session_id}] ë°˜ë³µ ë…¸ë“œ {node_id}: {iteration}íšŒì°¨ ì‹¤í–‰")

                # ë£¨í”„ ë³¸ë¬¸ ë…¸ë“œ ì‹¤í–‰ (ì²« ë²ˆì§¸ ìì‹ ë…¸ë“œë§Œ)
                # TODO: ì—¬ëŸ¬ ë…¸ë“œë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ë ¤ë©´ ìœ„ìƒ ì •ë ¬ í•„ìš”
                body_node_id = loop_body_node_ids[0]
                body_node = next((n for n in nodes if n.id == body_node_id), None)

                if body_node is None:
                    raise ValueError(f"ë£¨í”„ ë³¸ë¬¸ ë…¸ë“œ {body_node_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

                # ë£¨í”„ ë³¸ë¬¸ì´ Worker ë…¸ë“œì¸ ê²½ìš°ë§Œ ì§€ì› (í˜„ì¬ êµ¬í˜„)
                if body_node.type != "worker":
                    raise ValueError(
                        f"ë°˜ë³µ ë…¸ë“œëŠ” í˜„ì¬ Worker ë…¸ë“œë§Œ ì§€ì›í•©ë‹ˆë‹¤ (ë…¸ë“œ: {body_node_id}, íƒ€ì…: {body_node.type})"
                    )

                # Worker ë…¸ë“œ ì‹¤í–‰ (ê°„ì†Œí™”ëœ ë²„ì „)
                body_node_data: WorkerNodeData = body_node.data  # type: ignore
                agent_name = body_node_data.agent_name
                task_template = body_node_data.task_template

                # ì‘ì—… ì„¤ëª… ë Œë”ë§ (ì´ì „ ë°˜ë³µ ê²°ê³¼ í¬í•¨)
                task_description = self._render_task_template(
                    template=task_template,
                    node_id=body_node_id,
                    node_outputs=node_outputs,
                    initial_input=initial_input,
                )

                # Worker Agent ì‹¤í–‰
                agent_config = self._get_agent_config(agent_name)
                worker = WorkerAgent(config=agent_config, project_dir=project_path)
                body_output_chunks = []

                async for chunk in worker.execute_task(task_description):
                    body_output_chunks.append(chunk)
                    yield WorkflowNodeExecutionEvent(
                        event_type="node_output",
                        node_id=node_id,
                        data={"chunk": chunk},
                    )

                body_output = "".join(body_output_chunks)
                loop_output_history.append(body_output)

                # ë£¨í”„ ë³¸ë¬¸ ì¶œë ¥ì„ node_outputsì— ì €ì¥ (ë‹¤ìŒ ë°˜ë³µì—ì„œ ì‚¬ìš©)
                node_outputs[body_node_id] = body_output

                yield WorkflowNodeExecutionEvent(
                    event_type="node_output",
                    node_id=node_id,
                    data={"chunk": f"\n\n--- ë°˜ë³µ {iteration}íšŒì°¨ ì™„ë£Œ ---\n\n"},
                )

                # ì¡°ê±´ í‰ê°€ (ì¢…ë£Œ ì¡°ê±´ í™•ì¸)
                condition_met = self._evaluate_condition(
                    node_data.loop_condition_type,
                    node_data.loop_condition,
                    body_output
                )

                logger.info(
                    f"[{session_id}] ë°˜ë³µ ë…¸ë“œ {node_id}: ì¡°ê±´ í‰ê°€ ê²°ê³¼ = {condition_met}"
                )

                if condition_met:
                    logger.info(
                        f"[{session_id}] ë°˜ë³µ ë…¸ë“œ {node_id}: ì¡°ê±´ ë§Œì¡±, ë£¨í”„ ì¢…ë£Œ"
                    )
                    break

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            elapsed_time = time.time() - start_time

            # í†µí•© ì¶œë ¥ (ëª¨ë“  ë°˜ë³µ ê²°ê³¼ ê²°í•©)
            integrated_output = "\n\n---\n\n".join(loop_output_history)

            # ë…¸ë“œ ì™„ë£Œ ì´ë²¤íŠ¸
            yield WorkflowNodeExecutionEvent(
                event_type="node_complete",
                node_id=node_id,
                data={
                    "node_type": "loop",
                    "iterations": iteration,
                    "output": integrated_output,
                },
                timestamp=datetime.now().isoformat(),
                elapsed_time=elapsed_time,
            )

            logger.info(
                f"[{session_id}] ë°˜ë³µ ë…¸ë“œ ì™„ë£Œ: {node_id} ({iteration}íšŒ ë°˜ë³µ)"
            )

        except Exception as e:
            error_msg = f"ë°˜ë³µ ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
            logger.error(f"[{session_id}] {node_id}: {error_msg}", exc_info=True)

            elapsed_time = time.time() - start_time

            yield WorkflowNodeExecutionEvent(
                event_type="node_error",
                node_id=node_id,
                data={"error": error_msg},
                timestamp=datetime.now().isoformat(),
                elapsed_time=elapsed_time,
            )

            raise

    async def _execute_merge_node(
        self,
        node: WorkflowNode,
        node_outputs: Dict[str, str],
        edges: List[WorkflowEdge],
        session_id: str,
    ) -> str:
        """
        ë³‘í•© ë…¸ë“œ ì‹¤í–‰

        Args:
            node: ë³‘í•© ë…¸ë“œ
            node_outputs: ì´ì „ ë…¸ë“œ ì¶œë ¥ë“¤
            edges: ì—£ì§€ ëª©ë¡
            session_id: ì„¸ì…˜ ID

        Returns:
            str: ë³‘í•©ëœ ì¶œë ¥
        """
        node_id = node.id
        node_data: MergeNodeData = node.data  # type: ignore

        logger.info(
            f"[{session_id}] ë³‘í•© ë…¸ë“œ ì‹¤í–‰: {node_id} "
            f"(ì „ëµ: {node_data.merge_strategy})"
        )

        # ë¶€ëª¨ ë…¸ë“œ ì¶œë ¥ë“¤ ìˆ˜ì§‘
        parent_nodes = self._get_parent_nodes(node_id, edges)
        if not parent_nodes:
            raise ValueError(f"ë³‘í•© ë…¸ë“œ {node_id}ì— ë¶€ëª¨ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤")

        parent_outputs = [
            node_outputs.get(pid, "") for pid in parent_nodes
        ]

        # ë³‘í•© ì „ëµì— ë”°ë¼ ì¶œë ¥ ìƒì„±
        if node_data.merge_strategy == "concatenate":
            # ëª¨ë“  ì¶œë ¥ì„ êµ¬ë¶„ìë¡œ ê²°í•©
            merged_output = node_data.separator.join(parent_outputs)

        elif node_data.merge_strategy == "first":
            # ì²« ë²ˆì§¸ ì¶œë ¥ë§Œ ì‚¬ìš©
            merged_output = parent_outputs[0] if parent_outputs else ""

        elif node_data.merge_strategy == "last":
            # ë§ˆì§€ë§‰ ì¶œë ¥ë§Œ ì‚¬ìš©
            merged_output = parent_outputs[-1] if parent_outputs else ""

        elif node_data.merge_strategy == "custom":
            # ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ì‚¬ìš©
            if node_data.custom_template:
                merged_output = node_data.custom_template
                for i, output in enumerate(parent_outputs):
                    merged_output = merged_output.replace(f"{{{{branch_{i+1}}}}}", output)
            else:
                # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ concatenateë¡œ í´ë°±
                merged_output = node_data.separator.join(parent_outputs)

        else:
            logger.warning(
                f"ì•Œ ìˆ˜ ì—†ëŠ” ë³‘í•© ì „ëµ: {node_data.merge_strategy}, "
                "concatenateë¡œ í´ë°±í•©ë‹ˆë‹¤"
            )
            merged_output = node_data.separator.join(parent_outputs)

        logger.info(
            f"[{session_id}] ë³‘í•© ë…¸ë“œ ì™„ë£Œ: {node_id} "
            f"(ì…ë ¥: {len(parent_outputs)}ê°œ, ì¶œë ¥ ê¸¸ì´: {len(merged_output)})"
        )

        return merged_output

    async def _execute_manager_node(
        self,
        node: WorkflowNode,
        node_outputs: Dict[str, str],
        initial_input: str,
        session_id: str,
        project_path: Optional[str] = None,
    ) -> AsyncIterator[WorkflowNodeExecutionEvent]:
        """
        Manager ë…¸ë“œ ì‹¤í–‰ (ë³‘ë ¬ ì›Œì»¤ í˜¸ì¶œ)

        Manager ë…¸ë“œëŠ” ë“±ë¡ëœ ì›Œì»¤ë“¤ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í†µí•©í•©ë‹ˆë‹¤.

        Args:
            node: Manager ë…¸ë“œ
            node_outputs: ì´ì „ ë…¸ë“œ ì¶œë ¥ë“¤
            initial_input: ì´ˆê¸° ì…ë ¥
            session_id: ì„¸ì…˜ ID
            project_path: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (CLAUDE.md ë¡œë“œìš©)

        Yields:
            WorkflowNodeExecutionEvent: ë…¸ë“œ ì‹¤í–‰ ì´ë²¤íŠ¸
        """
        node_id = node.id
        node_data: ManagerNodeData = node.data  # type: ignore
        task_description = node_data.task_description
        available_workers = node_data.available_workers

        logger.info(
            f"[{session_id}] Manager ë…¸ë“œ ì‹¤í–‰: {node_id} "
            f"(ì›Œì»¤: {available_workers})"
        )

        # ë…¸ë“œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ë…¸ë“œ ì‹œì‘ ì´ë²¤íŠ¸
        start_event = WorkflowNodeExecutionEvent(
            event_type="node_start",
            node_id=node_id,
            data={
                "node_type": "manager",
                "available_workers": available_workers
            },
            timestamp=datetime.now().isoformat(),
        )
        yield start_event

        try:
            # ë“±ë¡ëœ ì›Œì»¤ë“¤ ë³‘ë ¬ ì‹¤í–‰
            worker_tasks = []
            for worker_name in available_workers:
                # Worker ì„¤ì • ì¡°íšŒ
                try:
                    worker_config = self._get_agent_config(worker_name)
                except ValueError as e:
                    logger.warning(
                        f"[{session_id}] ì›Œì»¤ '{worker_name}' ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"
                    )
                    continue

                # Worker Agent ìƒì„±
                worker = WorkerAgent(config=worker_config, project_dir=project_path)
                worker_tasks.append((worker_name, worker.execute_task(task_description)))

            # ë³‘ë ¬ ì‹¤í–‰ ë° ê²°ê³¼ ìˆ˜ì§‘
            worker_results: Dict[str, str] = {}

            for worker_name, worker_stream in worker_tasks:
                # ì›Œì»¤ ì‹œì‘ ë¡œê·¸
                yield WorkflowNodeExecutionEvent(
                    event_type="node_output",
                    node_id=node_id,
                    data={"chunk": f"\n\n--- {worker_name.upper()} ì‹¤í–‰ ì‹œì‘ ---\n\n"},
                )

                chunks = []
                async for chunk in worker_stream:
                    chunks.append(chunk)
                    # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
                    yield WorkflowNodeExecutionEvent(
                        event_type="node_output",
                        node_id=node_id,
                        data={"chunk": chunk},
                    )

                worker_output = "".join(chunks)
                worker_results[worker_name] = worker_output

                # ì›Œì»¤ ì™„ë£Œ ë¡œê·¸
                yield WorkflowNodeExecutionEvent(
                    event_type="node_output",
                    node_id=node_id,
                    data={"chunk": f"\n\n--- {worker_name.upper()} ì™„ë£Œ ---\n\n"},
                )

                logger.info(
                    f"[{session_id}] Manager ë…¸ë“œì˜ ì›Œì»¤ ì™„ë£Œ: {worker_name} "
                    f"(ì¶œë ¥ ê¸¸ì´: {len(worker_output)})"
                )

            # í†µí•© ê²°ê³¼ ìƒì„±
            integrated_output = "\n\n".join(
                f"## {worker_name.upper()} ê²°ê³¼\n\n{output}"
                for worker_name, output in worker_results.items()
            )

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            elapsed_time = time.time() - start_time

            # ë…¸ë“œ ì™„ë£Œ ì´ë²¤íŠ¸ (output í¬í•¨)
            complete_event = WorkflowNodeExecutionEvent(
                event_type="node_complete",
                node_id=node_id,
                data={
                    "node_type": "manager",
                    "workers_executed": list(worker_results.keys()),
                    "output_length": len(integrated_output),
                    "output": integrated_output,  # í†µí•© ê²°ê³¼ í¬í•¨
                },
                timestamp=datetime.now().isoformat(),
                elapsed_time=elapsed_time,
            )
            yield complete_event

            logger.info(
                f"[{session_id}] Manager ë…¸ë“œ ì™„ë£Œ: {node_id} "
                f"(ì¶œë ¥ ê¸¸ì´: {len(integrated_output)})"
            )

        except Exception as e:
            error_msg = f"Manager ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
            logger.error(f"[{session_id}] {node_id}: {error_msg}", exc_info=True)

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚° (ì—ëŸ¬ ë°œìƒê¹Œì§€ì˜ ì‹œê°„)
            elapsed_time = time.time() - start_time

            # ë…¸ë“œ ì—ëŸ¬ ì´ë²¤íŠ¸
            error_event = WorkflowNodeExecutionEvent(
                event_type="node_error",
                node_id=node_id,
                data={"error": error_msg},
                timestamp=datetime.now().isoformat(),
                elapsed_time=elapsed_time,
            )
            yield error_event

            raise

    async def execute_workflow(
        self,
        workflow: Workflow,
        initial_input: str,
        session_id: str,
        project_path: Optional[str] = None,
    ) -> AsyncIterator[WorkflowNodeExecutionEvent]:
        """
        ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            workflow: ì‹¤í–‰í•  ì›Œí¬í”Œë¡œìš°
            initial_input: ì´ˆê¸° ì…ë ¥ ë°ì´í„°
            session_id: ì„¸ì…˜ ID
            project_path: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì„¸ì…˜ë³„ ë¡œê·¸ ì €ì¥ìš©)

        Yields:
            WorkflowNodeExecutionEvent: ë…¸ë“œ ì‹¤í–‰ ì´ë²¤íŠ¸

        Raises:
            ValueError: ì›Œí¬í”Œë¡œìš° ì„¤ì • ì˜¤ë¥˜
            Exception: ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨
        """
        # ì„¸ì…˜ë³„ íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
        add_session_file_handlers(session_id, project_path)

        try:
            logger.info(
                f"[{session_id}] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘: {workflow.name} "
                f"(ë…¸ë“œ: {len(workflow.nodes)}, ì—£ì§€: {len(workflow.edges)})"
            )

            # ìœ„ìƒ ì •ë ¬
            try:
                sorted_nodes = self._topological_sort(workflow.nodes, workflow.edges)
            except ValueError as e:
                logger.error(f"[{session_id}] ì›Œí¬í”Œë¡œìš° ì •ë ¬ ì‹¤íŒ¨: {e}")
                raise

            logger.info(
                f"[{session_id}] ì‹¤í–‰ ìˆœì„œ: "
                f"{[node.id for node in sorted_nodes]}"
            )

            # ë…¸ë“œ ì¶œë ¥ ì €ì¥ (ë…¸ë“œ ID â†’ ì¶œë ¥)
            node_outputs: Dict[str, str] = {}

            # ê° ë…¸ë“œ ìˆœì°¨ ì‹¤í–‰
            for node in sorted_nodes:
                node_id = node.id

                # Input ë…¸ë“œ ì²˜ë¦¬ (í”„ë¡ íŠ¸ì—”ë“œ ì „ìš© ë…¸ë“œ - ìŠ¤í‚µ)
                if node.type == "input":
                    # Input ë…¸ë“œì˜ initial_inputì„ ë…¸ë“œ ì¶œë ¥ìœ¼ë¡œ ì €ì¥
                    # (ë‹¤ìŒ ë…¸ë“œê°€ {{node_<id>}} í˜•íƒœë¡œ ì°¸ì¡° ê°€ëŠ¥)
                    if isinstance(node.data, InputNodeData):
                        input_value = node.data.initial_input
                    elif isinstance(node.data, dict):
                        input_value = node.data.get("initial_input", initial_input)
                    else:
                        input_value = initial_input
                    node_outputs[node_id] = input_value

                    # ì‹œì‘ ì´ë²¤íŠ¸
                    yield WorkflowNodeExecutionEvent(
                        event_type="node_start",
                        node_id=node_id,
                        data={"agent_name": "Input"},
                        timestamp=datetime.now().isoformat(),
                    )

                    # ì™„ë£Œ ì´ë²¤íŠ¸ (Input ë…¸ë“œëŠ” ì¦‰ì‹œ ì™„ë£Œë˜ë¯€ë¡œ elapsed_timeì€ 0ì— ê°€ê¹Œì›€)
                    yield WorkflowNodeExecutionEvent(
                        event_type="node_complete",
                        node_id=node_id,
                        data={
                            "node_type": "input",
                            "agent_name": "Input",
                            "output_length": len(input_value),
                            "output": input_value,
                        },
                        timestamp=datetime.now().isoformat(),
                        elapsed_time=0.0,
                    )

                    logger.info(
                        f"[{session_id}] Input ë…¸ë“œ ì™„ë£Œ: {node_id} "
                        f"(ì¶œë ¥ ê¸¸ì´: {len(input_value)})"
                    )
                    continue  # ë‹¤ìŒ ë…¸ë“œë¡œ

                # Manager ë…¸ë“œ vs Worker ë…¸ë“œ vs ì¡°ê±´/ë°˜ë³µ/ë³‘í•© ë…¸ë“œ êµ¬ë¶„
                elif node.type == "manager":
                    # Manager ë…¸ë“œ ì‹¤í–‰
                    async for event in self._execute_manager_node(
                        node, node_outputs, initial_input, session_id, project_path
                    ):
                        if event.event_type == "node_complete":
                            # í†µí•© ê²°ê³¼ ì €ì¥
                            node_outputs[node_id] = event.data.get("output", "")
                        yield event

                elif node.type == "condition":
                    # ì¡°ê±´ ë¶„ê¸° ë…¸ë“œ ì‹¤í–‰
                    start_time = time.time()

                    # ì‹œì‘ ì´ë²¤íŠ¸
                    yield WorkflowNodeExecutionEvent(
                        event_type="node_start",
                        node_id=node_id,
                        data={"node_type": "condition"},
                        timestamp=datetime.now().isoformat(),
                    )

                    try:
                        next_node_id, result_text = await self._execute_condition_node(
                            node, node_outputs, workflow.edges, session_id
                        )

                        # ì¡°ê±´ ê²°ê³¼ ì €ì¥
                        node_outputs[node_id] = result_text

                        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
                        elapsed_time = time.time() - start_time

                        # ì™„ë£Œ ì´ë²¤íŠ¸
                        yield WorkflowNodeExecutionEvent(
                            event_type="node_complete",
                            node_id=node_id,
                            data={
                                "node_type": "condition",
                                "next_node": next_node_id,
                                "output": result_text,
                            },
                            timestamp=datetime.now().isoformat(),
                            elapsed_time=elapsed_time,
                        )

                        logger.info(
                            f"[{session_id}] ì¡°ê±´ ë…¸ë“œ ì™„ë£Œ: {node_id} â†’ {next_node_id}"
                        )

                    except Exception as e:
                        error_msg = f"ì¡°ê±´ ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
                        logger.error(f"[{session_id}] {node_id}: {error_msg}", exc_info=True)

                        elapsed_time = time.time() - start_time

                        yield WorkflowNodeExecutionEvent(
                            event_type="node_error",
                            node_id=node_id,
                            data={"error": error_msg},
                            timestamp=datetime.now().isoformat(),
                            elapsed_time=elapsed_time,
                        )

                        raise

                elif node.type == "loop":
                    # ë°˜ë³µ ë…¸ë“œ ì‹¤í–‰
                    async for event in self._execute_loop_node(
                        node, node_outputs, workflow.edges, workflow.nodes,
                        initial_input, session_id, project_path
                    ):
                        if event.event_type == "node_complete":
                            # í†µí•© ê²°ê³¼ ì €ì¥
                            node_outputs[node_id] = event.data.get("output", "")
                        yield event

                elif node.type == "merge":
                    # ë³‘í•© ë…¸ë“œ ì‹¤í–‰
                    start_time = time.time()

                    # ì‹œì‘ ì´ë²¤íŠ¸
                    yield WorkflowNodeExecutionEvent(
                        event_type="node_start",
                        node_id=node_id,
                        data={"node_type": "merge"},
                        timestamp=datetime.now().isoformat(),
                    )

                    try:
                        merged_output = await self._execute_merge_node(
                            node, node_outputs, workflow.edges, session_id
                        )

                        # ë³‘í•© ê²°ê³¼ ì €ì¥
                        node_outputs[node_id] = merged_output

                        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
                        elapsed_time = time.time() - start_time

                        # ì™„ë£Œ ì´ë²¤íŠ¸
                        yield WorkflowNodeExecutionEvent(
                            event_type="node_complete",
                            node_id=node_id,
                            data={
                                "node_type": "merge",
                                "output_length": len(merged_output),
                                "output": merged_output,
                            },
                            timestamp=datetime.now().isoformat(),
                            elapsed_time=elapsed_time,
                        )

                        logger.info(
                            f"[{session_id}] ë³‘í•© ë…¸ë“œ ì™„ë£Œ: {node_id} "
                            f"(ì¶œë ¥ ê¸¸ì´: {len(merged_output)})"
                        )

                    except Exception as e:
                        error_msg = f"ë³‘í•© ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
                        logger.error(f"[{session_id}] {node_id}: {error_msg}", exc_info=True)

                        elapsed_time = time.time() - start_time

                        yield WorkflowNodeExecutionEvent(
                            event_type="node_error",
                            node_id=node_id,
                            data={"error": error_msg},
                            timestamp=datetime.now().isoformat(),
                            elapsed_time=elapsed_time,
                        )

                        raise

                else:
                    # Worker ë…¸ë“œ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§)
                    # node.dataê°€ dictì¸ ê²½ìš° ì²˜ë¦¬
                    if isinstance(node.data, dict):
                        agent_name = node.data.get("agent_name")
                        task_template = node.data.get("task_template")
                        allowed_tools_override = node.data.get("allowed_tools")
                        thinking_override = node.data.get("thinking")

                        if not agent_name:
                            raise ValueError(f"ë…¸ë“œ {node_id}: agent_nameì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                        if not task_template:
                            raise ValueError(f"ë…¸ë“œ {node_id}: task_templateì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                    else:
                        # WorkerNodeData ê°ì²´ì¸ ê²½ìš°
                        node_data: WorkerNodeData = node.data  # type: ignore
                        agent_name = node_data.agent_name
                        task_template = node_data.task_template
                        allowed_tools_override = node_data.allowed_tools
                        thinking_override = node_data.thinking

                    # ë…¸ë“œ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                    start_time = time.time()

                    # ë…¸ë“œ ì‹œì‘ ì´ë²¤íŠ¸
                    start_event = WorkflowNodeExecutionEvent(
                        event_type="node_start",
                        node_id=node_id,
                        data={"agent_name": agent_name},
                        timestamp=datetime.now().isoformat(),
                    )
                    logger.info(f"[{session_id}] ğŸŸ¢ ì´ë²¤íŠ¸ ìƒì„±: node_start (node: {node_id}, agent: {agent_name})")
                    yield start_event

                    try:
                        # Agent ì„¤ì • ì¡°íšŒ
                        agent_config = self._get_agent_config(agent_name)

                        # allowed_tools ì˜¤ë²„ë¼ì´ë“œ (ë…¸ë“œì—ì„œ ì§€ì •í•œ ê²½ìš°)
                        if allowed_tools_override is not None:
                            agent_config = replace(agent_config, allowed_tools=allowed_tools_override)
                            logger.info(
                                f"[{session_id}] ë…¸ë“œ {node_id}: allowed_tools ì˜¤ë²„ë¼ì´ë“œ "
                                f"({len(allowed_tools_override)}ê°œ ë„êµ¬)"
                            )

                        # thinking ëª¨ë“œ ì˜¤ë²„ë¼ì´ë“œ (ë…¸ë“œì—ì„œ ì§€ì •í•œ ê²½ìš°)
                        if thinking_override is not None:
                            agent_config = replace(agent_config, thinking=thinking_override)
                            logger.info(
                                f"[{session_id}] ë…¸ë“œ {node_id}: thinking ëª¨ë“œ ì˜¤ë²„ë¼ì´ë“œ "
                                f"(thinking={thinking_override})"
                            )

                        # ì‘ì—… ì„¤ëª… ë Œë”ë§
                        parent_nodes = self._get_parent_nodes(node_id, workflow.edges)
                        parent_outputs = {
                            pid: node_outputs[pid] for pid in parent_nodes
                            if pid in node_outputs
                        }

                        task_description = self._render_task_template(
                            template=task_template,
                            node_id=node_id,
                            node_outputs=parent_outputs,
                            initial_input=initial_input,
                        )

                        logger.info(
                            f"[{session_id}] ë…¸ë“œ ì‹¤í–‰: {node_id} ({agent_name}) "
                            f"- ì‘ì—… ê¸¸ì´: {len(task_description)}"
                        )

                        # Worker Agent ì‹¤í–‰
                        worker = WorkerAgent(config=agent_config, project_dir=project_path)
                        node_output_chunks = []

                        # í† í° ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘ì„ ìœ„í•œ ë³€ìˆ˜
                        node_token_usage: Optional[TokenUsage] = None

                        def usage_callback(usage_info: Dict[str, Any]):
                            """í† í° ì‚¬ìš©ëŸ‰ ì½œë°±"""
                            nonlocal node_token_usage
                            node_token_usage = TokenUsage(
                                input_tokens=usage_info.get("input_tokens", 0),
                                output_tokens=usage_info.get("output_tokens", 0),
                                total_tokens=usage_info.get("total_tokens", 0),
                            )
                            logger.debug(
                                f"[{session_id}] ğŸ’° í† í° ì‚¬ìš©ëŸ‰: {node_token_usage.total_tokens} "
                                f"(ì…ë ¥: {node_token_usage.input_tokens}, ì¶œë ¥: {node_token_usage.output_tokens})"
                            )

                        async for chunk in worker.execute_task(task_description, usage_callback=usage_callback):
                            node_output_chunks.append(chunk)

                            # ë…¸ë“œ ì¶œë ¥ ì´ë²¤íŠ¸ (ìŠ¤íŠ¸ë¦¬ë°)
                            output_event = WorkflowNodeExecutionEvent(
                                event_type="node_output",
                                node_id=node_id,
                                data={"chunk": chunk},
                            )
                            logger.debug(f"[{session_id}] ğŸ“ ì´ë²¤íŠ¸ ìƒì„±: node_output (node: {node_id}, chunk: {len(chunk)}ì)")
                            yield output_event

                        # ë…¸ë“œ ì¶œë ¥ ì €ì¥
                        node_output = "".join(node_output_chunks)
                        node_outputs[node_id] = node_output

                        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
                        elapsed_time = time.time() - start_time

                        # ë…¸ë“œ ì™„ë£Œ ì´ë²¤íŠ¸
                        complete_event = WorkflowNodeExecutionEvent(
                            event_type="node_complete",
                            node_id=node_id,
                            data={
                                "agent_name": agent_name,
                                "output_length": len(node_output),
                            },
                            timestamp=datetime.now().isoformat(),
                            elapsed_time=elapsed_time,
                            token_usage=node_token_usage,
                        )
                        logger.info(f"[{session_id}] âœ… ì´ë²¤íŠ¸ ìƒì„±: node_complete (node: {node_id}, agent: {agent_name})")
                        yield complete_event

                        logger.info(
                            f"[{session_id}] ë…¸ë“œ ì™„ë£Œ: {node_id} ({agent_name}) "
                            f"- ì¶œë ¥ ê¸¸ì´: {len(node_output)}"
                        )

                    except Exception as e:
                        error_msg = f"ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
                        logger.error(f"[{session_id}] {node_id}: {error_msg}", exc_info=True)

                        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚° (ì—ëŸ¬ ë°œìƒê¹Œì§€ì˜ ì‹œê°„)
                        elapsed_time = time.time() - start_time

                        # ë…¸ë“œ ì—ëŸ¬ ì´ë²¤íŠ¸
                        error_event = WorkflowNodeExecutionEvent(
                            event_type="node_error",
                            node_id=node_id,
                            data={"error": error_msg},
                            timestamp=datetime.now().isoformat(),
                            elapsed_time=elapsed_time,
                        )
                        logger.error(f"[{session_id}] ğŸ”´ ì´ë²¤íŠ¸ ìƒì„±: node_error (node: {node_id})")
                        yield error_event

                        # ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨
                        raise

            logger.info(f"[{session_id}] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {workflow.name}")

            # ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì´ë²¤íŠ¸
            workflow_complete_event = WorkflowNodeExecutionEvent(
                event_type="workflow_complete",
                node_id="",
                data={"message": "ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ"},
                timestamp=datetime.now().isoformat(),
            )
            logger.info(f"[{session_id}] ğŸ‰ ì´ë²¤íŠ¸ ìƒì„±: workflow_complete")
            yield workflow_complete_event

        finally:
            # ì„¸ì…˜ë³„ íŒŒì¼ í•¸ë“¤ëŸ¬ ì œê±° (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
            remove_session_file_handlers(session_id)
